@Article{Cortes1995,
author="Cortes, Corinna
and Vapnik, Vladimir",
title="Support-vector networks",
journal="Machine Learning",
year="1995",
month="Sep",
day="01",
volume="20",
number="3",
pages="273--297",
abstract="The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.",
issn="1573-0565",
doi="10.1007/BF00994018"
}
@InProceedings{pmlr-v20-biggio11,
  title = 	 {Support Vector Machines Under Adversarial Label Noise},
  author = 	 {Battista Biggio and Blaine Nelson and Pavel Laskov},
  booktitle = 	 {Proceedings of the Asian Conference on Machine Learning},
  pages = 	 {97--112},
  year = 	 {2011},
  volume = 	 {20},
  publisher = 	 {PMLR}
}
@ARTICLE{Wu03probabilityestimates,
    author = {Tingfan Wu and ChihJen Lin and Ruby C. Weng},
    title = {Probability Estimates for Multi-class Classification by Pairwise Coupling},
    journal = {Journal of Machine Learning Research},
    year = {2003},
    volume = {5},
    pages = {975--1005}
}
@article{liu2016classification,
  title={Classification with noisy labels by importance reweighting},
  author={Liu, Tongliang and Tao, Dacheng},
  journal={IEEE Transactions on pattern analysis and machine intelligence},
  volume={38},
  number={3},
  pages={447--461},
  year={2016},
  publisher={IEEE}
}
@book{hardle2007applied,
  title={Applied multivariate statistical analysis},
  author={H{\"a}rdle, Wolfgang and Simar, L{\'e}opold},
  volume={22007},
  year={2007},
  publisher={Springer}
}
@article{frenay2014classification,
  title={Classification in the presence of label noise: a survey},
  author={Fr{\'e}nay, Beno{\^\i}t and Verleysen, Michel},
  journal={IEEE transactions on neural networks and learning systems},
  volume={25},
  number={5},
  pages={845--869},
  year={2014},
  publisher={IEEE}
}
@article{yang2018adasampling,
  title={AdaSampling for Positive-Unlabeled and Label Noise Learning With Bioinformatics Applications},
  author={Yang, Pengyi and Ormerod, John T and Liu, Wei and Ma, Chendong and Zomaya, Albert Y and Yang, Jean YH},
  journal={IEEE Transactions on Cybernetics},
  number={99},
  pages={1--12},
  year={2018},
  publisher={IEEE}
}
@inproceedings{Boser:1992:TAO:130385.130401,
 author = {Boser, Bernhard E. and Guyon, Isabelle M. and Vapnik, Vladimir N.},
 title = {A Training Algorithm for Optimal Margin Classifiers},
 booktitle = {Proceedings of the Fifth Annual Workshop on Computational Learning Theory},
 series = {COLT '92},
 year = {1992},
 isbn = {0-89791-497-X},
 location = {Pittsburgh, Pennsylvania, USA},
 pages = {144--152},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/130385.130401},
 doi = {10.1145/130385.130401},
 acmid = {130401},
 publisher = {ACM},
 address = {New York, NY, USA},
} 
@book{hastie01statisticallearning,
  added-at = {2008-05-16T16:17:42.000+0200},
  address = {New York, NY, USA},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  biburl = {https://www.bibsonomy.org/bibtex/2f58afc5c9793fcc8ad8389824e57984c/sb3000},
  interhash = {d585aea274f2b9b228fc1629bc273644},
  intrahash = {f58afc5c9793fcc8ad8389824e57984c},
  keywords = {ml statistics},
  publisher = {Springer New York Inc.},
  series = {Springer Series in Statistics},
  timestamp = {2008-05-16T16:17:43.000+0200},
  title = {The Elements of Statistical Learning},
  year = 2001
}
@article{Fernandez-Delgado:2014:WNH:2627435.2697065,
 author = {Fern\'{a}ndez-Delgado, Manuel and Cernadas, Eva and Barro, Sen{\'e}n and Amorim, Dinani},
 title = {Do We Need Hundreds of Classifiers to Solve Real World Classification Problems?},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2014},
 volume = {15},
 number = {1},
 month = jan,
 year = {2014},
 issn = {1532-4435},
 pages = {3133--3181},
 numpages = {49},
 url = {http://dl.acm.org/citation.cfm?id=2627435.2697065},
 acmid = {2697065},
 publisher = {JMLR.org},
 keywords = {Bayesian classifiers, UCI data base, classification, decision trees, discriminant analysis, ensembles, generalized linear models, logistic and multinomial regression, multiple adaptive regression splines, nearest-neighbors, neural networks, partial least squares and principal component regression, random forest, rule-based classifiers, support vector machine},
} 
@incollection{NIPS2012_4500,
title = {Dimensionality Dependent PAC-Bayes Margin Bound},
author = {Jin, Chi and Wang, Liwei},
booktitle = {Advances in Neural Information Processing Systems 25},
editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
pages = {1034--1042},
year = {2012},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/4500-dimensionality-dependent-pac-bayes-margin-bound.pdf}
}
