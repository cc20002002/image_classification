\expandafter\ifx\csname doTocEntry\endcsname\relax \expandafter\endinput\fi 
\doTocEntry\toclikesection{}{\csname a:TocLink\endcsname{1}{x1-1000}{QQ2-1-1}{Contents}}{1}\relax 
\doTocEntry\tocsection{1}{\csname a:TocLink\endcsname{1}{x1-20001}{QQ2-1-2}{Introduction}}{3}\relax 
\doTocEntry\tocsection{2}{\csname a:TocLink\endcsname{1}{x1-30002}{QQ2-1-3}{Related work}}{3}\relax 
\doTocEntry\tocsection{3}{\csname a:TocLink\endcsname{1}{x1-40003}{QQ2-1-4}{Methods}}{4}\relax 
\doTocEntry\tocsubsection{3.1}{\csname a:TocLink\endcsname{1}{x1-50003.1}{QQ2-1-5}{Base model: support vector machine}}{4}\relax 
\doTocEntry\tocsubsubsection{3.1.1}{\csname a:TocLink\endcsname{1}{x1-60003.1.1}{QQ2-1-6}{Support vector machine resists over-fitting}}{5}\relax 
\doTocEntry\tocsubsubsection{3.1.2}{\csname a:TocLink\endcsname{1}{x1-70003.1.2}{QQ2-1-7}{Support vector machine is not robust to label noise}}{5}\relax 
\doTocEntry\tocsubsection{3.2}{\csname a:TocLink\endcsname{1}{x1-80003.2}{QQ2-1-8}{Preprocess}}{6}\relax 
\doTocEntry\tocsubsubsection{3.2.1}{\csname a:TocLink\endcsname{1}{x1-90003.2.1}{QQ2-1-9}{Photometric normalisation improves classification performance}}{6}\relax 
\doTocEntry\tocsubsubsection{3.2.2}{\csname a:TocLink\endcsname{1}{x1-100003.2.2}{QQ2-1-10}{Principal component analysis reduces dimensionality}}{6}\relax 
\doTocEntry\tocsubsection{3.3}{\csname a:TocLink\endcsname{1}{x1-110003.3}{QQ2-1-11}{The original dataset is balanced}}{6}\relax 
\doTocEntry\tocsubsection{3.4}{\csname a:TocLink\endcsname{1}{x1-120003.4}{QQ2-1-12}{Flip rates estimation}}{8}\relax 
\doTocEntry\tocsubsubsection{3.4.1}{\csname a:TocLink\endcsname{1}{x1-130003.4.1}{QQ2-1-13}{Density ratio method estimates conditional probability}}{8}\relax 
\doTocEntry\tocsubsubsection{3.4.2}{\csname a:TocLink\endcsname{1}{x1-140003.4.2}{QQ2-1-14}{Minimum of conditional probability estimates flip rates}}{10}\relax 
\doTocEntry\tocsubsection{3.5}{\csname a:TocLink\endcsname{1}{x1-150003.5}{QQ2-1-15}{Method 1: Expectation Maximisation}}{11}\relax 
\doTocEntry\tocsubsubsection{3.5.1}{\csname a:TocLink\endcsname{1}{x1-160003.5.1}{QQ2-1-16}{Expectation Maximisation derives loss function}}{11}\relax 
\doTocEntry\tocsubsubsection{3.5.2}{\csname a:TocLink\endcsname{1}{x1-170003.5.2}{QQ2-1-17}{Bernoulli random variable models latent label noise}}{11}\relax 
\doTocEntry\tocsubsubsection{3.5.3}{\csname a:TocLink\endcsname{1}{x1-180003.5.3}{QQ2-1-18}{Modifying kernel improves robustness against label noise}}{12}\relax 
\doTocEntry\toclol{}{\csname a:TocLink\endcsname{1}{x1-18002}{}{\numberline {1}Customised kernel for Expectation Maximisation algorithm}}{13}\relax 
\doTocEntry\tocsubsubsection{3.5.4}{\csname a:TocLink\endcsname{1}{x1-190003.5.4}{QQ2-1-20}{Proof: proposed kernel matrix is positive definite}}{13}\relax 
\doTocEntry\tocsubsection{3.6}{\csname a:TocLink\endcsname{1}{x1-200003.6}{QQ2-1-21}{Method 2: Importance Reweighting}}{14}\relax 
\doTocEntry\tocsubsubsection{3.6.1}{\csname a:TocLink\endcsname{1}{x1-210003.6.1}{QQ2-1-22}{Sigmoid function estimates conditional probability}}{14}\relax 
\doTocEntry\tocsubsubsection{3.6.2}{\csname a:TocLink\endcsname{1}{x1-220003.6.2}{QQ2-1-23}{Reweighting coefficient improves robustness against label noise}}{15}\relax 
\doTocEntry\tocsubsection{3.7}{\csname a:TocLink\endcsname{1}{x1-230003.7}{QQ2-1-24}{Method 3: heuristic approach by relabelling}}{17}\relax 
\doTocEntry\tocsubsubsection{3.7.1}{\csname a:TocLink\endcsname{1}{x1-240003.7.1}{QQ2-1-25}{Conditional probability filters samples}}{17}\relax 
\doTocEntry\tocsubsubsection{3.7.2}{\csname a:TocLink\endcsname{1}{x1-250003.7.2}{QQ2-1-26}{Pre-training model corrects labels}}{17}\relax 
\doTocEntry\tocsubsection{3.8}{\csname a:TocLink\endcsname{1}{x1-260003.8}{QQ2-1-27}{Tuning hyperparameters}}{18}\relax 
\doTocEntry\tocsubsection{3.9}{\csname a:TocLink\endcsname{1}{x1-270003.9}{QQ2-1-28}{Bootstrap constructs confidence intervals and hypothesis tests}}{18}\relax 
\doTocEntry\tocsubsubsection{3.9.1}{\csname a:TocLink\endcsname{1}{x1-280003.9.1}{QQ2-1-29}{Bootstrapping percentile confidence intervals}}{19}\relax 
\doTocEntry\tocsubsubsection{3.9.2}{\csname a:TocLink\endcsname{1}{x1-290003.9.2}{QQ2-1-30}{Kolmogorov-Smirnov test compares the accuracy of algorithms}}{19}\relax 
\doTocEntry\tocsection{4}{\csname a:TocLink\endcsname{1}{x1-300004}{QQ2-1-31}{Experiments}}{20}\relax 
\doTocEntry\tocsubsection{4.1}{\csname a:TocLink\endcsname{1}{x1-310004.1}{QQ2-1-32}{Experiment Setting}}{20}\relax 
\doTocEntry\toclol{}{\csname a:TocLink\endcsname{1}{x1-31002}{}{\numberline {2}Multi-threading using the \texttt  {multiprocessing} package of \texttt  {Python}.}}{20}\relax 
\doTocEntry\toclof{1}{\csname a:TocLink\endcsname{1}{x1-310081}{}{\ignorespaces HPC}}{figure}\relax 
\doTocEntry\tocsubsection{4.2}{\csname a:TocLink\endcsname{1}{x1-320004.2}{QQ2-1-35}{Preprocessing}}{23}\relax 
\doTocEntry\tocsubsubsection{4.2.1}{\csname a:TocLink\endcsname{1}{x1-330004.2.1}{QQ2-1-36}{Photometric normalisation improves convergence}}{23}\relax 
\doTocEntry\tocsubsubsection{4.2.2}{\csname a:TocLink\endcsname{1}{x1-340004.2.2}{QQ2-1-37}{Principal component analysis speeds up algorithms}}{23}\relax 
\doTocEntry\toclof{2}{\csname a:TocLink\endcsname{1}{x1-340012}{}{\ignorespaces Comparison between original images and processed images. The first row shows the original images. The second row shows the images after applying photometric normalisation. The third row shows the \textsc  {pca}-processed images.}}{figure}\relax 
\doTocEntry\toclot{1}{\csname a:TocLink\endcsname{1}{x1-340021}{}{\ignorespaces Mean, standard deviation and confidence interval of accuracy and average running time for combinations of algorithm and datasets. In the algorithm column, \textsc  {em} represents the Expectation Maximisation, \textsc  {ir} represents Importance Reweighting and \textsc  {r} represents Relabelling. }}{table}\relax 
\doTocEntry\tocsubsection{4.3}{\csname a:TocLink\endcsname{1}{x1-350004.3}{QQ2-1-40}{Discuss flip rate}}{29}\relax 
\doTocEntry\tocsubsection{4.4}{\csname a:TocLink\endcsname{1}{x1-360004.4}{QQ2-1-41}{Selected hyperparameters}}{29}\relax 
\doTocEntry\tocsubsubsection{4.4.1}{\csname a:TocLink\endcsname{1}{x1-370004.4.1}{QQ2-1-42}{Hyperparameters for algorithms}}{29}\relax 
\doTocEntry\toclot{2}{\csname a:TocLink\endcsname{1}{x1-370012}{}{\ignorespaces Selected hyperparameters for classification models against \textsc  {ccn}. The hyperparameters with subscript\nobreakspace  {}$1$, that is, the bandwidth\nobreakspace  {}$\gamma _1$ and soft margin regularisation\nobreakspace  {}$\frac  {1}{2n\lambda _1}$, are for the pre-training models. Those with subscript\nobreakspace  {}$2$ are for the classification model. Note that Expectation Maximisation do not have a pre-training model. In the algorithm column, \textsc  {em} represents the algorithm of Expectation Maximisation, \textsc  {ir} represents the algorithm Importance Reweighting and \textsc  {r} represents the algorithm of Relabelling.}}{table}\relax 
\doTocEntry\tocsubsubsection{4.4.2}{\csname a:TocLink\endcsname{1}{x1-380004.4.2}{QQ2-1-44}{Hyperparameters for algorithms}}{32}\relax 
\doTocEntry\tocsubsection{4.5}{\csname a:TocLink\endcsname{1}{x1-390004.5}{QQ2-1-45}{Regression estimates running time}}{32}\relax 
\doTocEntry\toclof{3}{\csname a:TocLink\endcsname{1}{x1-390013}{}{\ignorespaces  Number of samples versus average running time on a log-log scale. The slope of the straight lines on this scale approximates the computational complexity in sample size\nobreakspace  {}$n$. The ratio for a pair of points from the same algorithm and sample size approximates complexity in number of features\nobreakspace  {}$p$. }}{figure}\relax 
\doTocEntry\tocsubsection{4.6}{\csname a:TocLink\endcsname{1}{x1-400004.6}{QQ2-1-47}{Compare algorithms and datasets}}{35}\relax 
\doTocEntry\tocsubsubsection{4.6.1}{\csname a:TocLink\endcsname{1}{x1-410004.6.1}{QQ2-1-48}{Hypothesis tests justify visualisations}}{35}\relax 
\doTocEntry\toclot{3}{\csname a:TocLink\endcsname{1}{x1-410013}{}{\ignorespaces The result of hypothesis test with training sample size of $8,000$. The result is `reject' indicates we have statistical evidence at $95\%$ confidence level to conclude one algorithm is more accurate than the other.}}{table}\relax 
\doTocEntry\toclof{4}{\csname a:TocLink\endcsname{1}{x1-410024}{}{\ignorespaces The density function of accuracy estimated by kernel smoothing. The three colours correspond to three algorithms. The left density plots are estimated using the fashion-\textsc  {mnist} dataset, where as the middle and right density plots are estimated from \textsc  {cifar} dataset.}}{figure}\relax 
\doTocEntry\tocsubsubsection{4.6.2}{\csname a:TocLink\endcsname{1}{x1-420004.6.2}{QQ2-1-51}{Expectation Maximisation is the fastest}}{41}\relax 
\doTocEntry\tocsubsubsection{4.6.3}{\csname a:TocLink\endcsname{1}{x1-430004.6.3}{QQ2-1-52}{\textsc  {cifar} is more difficult to classify}}{41}\relax 
\doTocEntry\toclof{5}{\csname a:TocLink\endcsname{1}{x1-430015}{}{\ignorespaces Box plots of the accuracy results against running time. Different colours of borders represent different learning algorithms. Different colours filling the boxes represent the two original datasets and \textsc  {pca} preprocessed \textsc  {cifar}. The vertical edges of boxes represent the $1$st and $3$rd quantiles of accuracy for each setting, and the end of vertical lines represent $1.5$ inter quantile range from these two quantiles. The dots are outliers. The right two boxes and the third bottom middle pink box are accuracy classifying original \textsc  {cifar} dataset. The bottom left three boxes are accuracy of classifying the \textsc  {cifar} dataset with \textsc  {pca}. The top left three boxes are accuracy classifying fashion-\textsc  {mnist} dataset.}}{figure}\relax 
\doTocEntry\tocsubsubsection{4.6.4}{\csname a:TocLink\endcsname{1}{x1-440004.6.4}{QQ2-1-54}{Relabelling approach is inconsistent and less robust}}{44}\relax 
\doTocEntry\toclof{6}{\csname a:TocLink\endcsname{1}{x1-440016}{}{\ignorespaces The accuracy of algorithms versus sample size for all three methods on both datasets. The sample size increases from $2,000$ to $10,000$. The coloured regions near the lines indicate a $95\%$ confidence interval. Three colours of the lines represent different algorithms. The three node shapes and the colours filling the confidence intervals correspond to different datasets. }}{figure}\relax 
\doTocEntry\tocsubsection{4.7}{\csname a:TocLink\endcsname{1}{x1-450004.7}{QQ2-1-56}{Discussion and personal reflection}}{47}\relax 
\doTocEntry\tocsection{5}{\csname a:TocLink\endcsname{1}{x1-460005}{QQ2-1-57}{Conclusion}}{48}\relax 
\doTocEntry\toclikesection{}{\csname a:TocLink\endcsname{1}{x1-470005}{QQ2-1-58}{References}}{48}\relax 
\par 
