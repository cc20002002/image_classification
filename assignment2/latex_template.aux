\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{hardle2007applied}
\citation{Bishop:2006:PRM:1162264}
\citation{pmlr-v20-biggio11}
\citation{liu2016classification}
\citation{brodley1996identifying}
\citation{NIPS2012_4500,Seeger:2003:PGE:944919.944929,Cortes1995}
\citation{Fernandez-Delgado:2014:WNH:2627435.2697065}
\citation{frenay2014classification}
\citation{liu2016classification}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{frenay2014classification}
\citation{frenay2014classification}
\citation{yang2018adasampling}
\citation{pmlr-v20-biggio11}
\citation{liu2016classification}
\citation{liu2016classification}
\citation{Boser:1992:TAO:130385.130401}
\citation{Cortes1995}
\citation{Fernandez-Delgado:2014:WNH:2627435.2697065}
\citation{hastie01statisticallearning}
\citation{hastie01statisticallearning}
\citation{NIPS2012_4500}
\citation{Cortes1995,Seeger:2003:PGE:944919.944929}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related work}{2}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methods}{2}{section.3}}
\newlabel{method}{{3}{2}{Methods}{section.3}{}}
\newlabel{eq:noise}{{1}{2}{Methods}{equation.3.1}{}}
\newlabel{eq:decision}{{2}{2}{Methods}{equation.3.2}{}}
\citation{Fernandez-Delgado:2014:WNH:2627435.2697065}
\citation{frenay2014classification}
\citation{frenay2014classification}
\citation{jonsson2002support}
\citation{jonsson2002support}
\citation{liu2016classification}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Preprocess}{3}{subsection.3.1}}
\newlabel{preproc}{{3.1}{3}{Preprocess}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Photometric normalisation improves classification performance}{3}{subsubsection.3.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Principle component analysis reduces dimensionality}{3}{subsubsection.3.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}The original data set is balanced}{3}{subsection.3.2}}
\newlabel{sec:1}{{3.2}{3}{The original data set is balanced}{subsection.3.2}{}}
\newlabel{eq:ps}{{3}{3}{The original data set is balanced}{equation.3.3}{}}
\newlabel{eq:exp}{{4}{3}{The original data set is balanced}{equation.3.4}{}}
\citation{DBLP:journals/jmlr/KanamoriHS09}
\citation{liu2016classification}
\citation{pmlr-v20-biggio11}
\citation{pmlr-v20-biggio11}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Flip rates estimation}{4}{subsection.3.3}}
\newlabel{method2}{{3.3}{4}{Flip rates estimation}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Density ratio method estimates conditional probability}{4}{subsubsection.3.3.1}}
\newlabel{method22}{{3.3.1}{4}{Density ratio method estimates conditional probability}{subsubsection.3.3.1}{}}
\newlabel{eq:baye}{{5}{4}{Density ratio method estimates conditional probability}{equation.3.5}{}}
\newlabel{eq:gauss}{{6}{4}{Density ratio method estimates conditional probability}{equation.3.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Estimate flip rates}{4}{subsubsection.3.3.2}}
\newlabel{method23}{{3.3.2}{4}{Estimate flip rates}{subsubsection.3.3.2}{}}
\newlabel{eq:fliprate}{{3.3.2}{4}{Estimate flip rates}{subsubsection.3.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Method 1: Expectation Maximisation}{4}{subsection.3.4}}
\newlabel{1st}{{3.4}{4}{Method 1: Expectation Maximisation}{subsection.3.4}{}}
\citation{pmlr-v20-biggio11}
\citation{hastie01statisticallearning}
\citation{liu2016classification}
\citation{liu2016classification}
\citation{liu2016classification}
\citation{Sugiyama10densityratio}
\citation{liu2016classification}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Expectation Maximisation derives loss function}{5}{subsubsection.3.4.1}}
\newlabel{eq:dual}{{7}{5}{Expectation Maximisation derives loss function}{equation.3.7}{}}
\newlabel{eq:dual2}{{8}{5}{Expectation Maximisation derives loss function}{equation.3.8}{}}
\newlabel{eq:dual3}{{9}{5}{Expectation Maximisation derives loss function}{equation.3.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Modifying kernel improves robustness against label noise}{5}{subsubsection.3.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Method 2: Importance Reweighting}{5}{subsection.3.5}}
\newlabel{3rd}{{3.5}{5}{Method 2: Importance Reweighting}{subsection.3.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.1}Sigmoid function estimates conditional probability}{5}{subsubsection.3.5.1}}
\newlabel{sigmoid}{{3.5.1}{5}{Sigmoid function estimates conditional probability}{subsubsection.3.5.1}{}}
\citation{Platt99probabilisticoutputs}
\citation{liu2016classification}
\citation{liu2016classification}
\citation{liu2016classification}
\citation{Wu03probabilityestimates}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.2}Reweighting coefficient improves robustness against label noise.}{6}{subsubsection.3.5.2}}
\newlabel{beta}{{10}{6}{Reweighting coefficient improves robustness against label noise}{equation.3.10}{}}
\newlabel{eq:weighting}{{12}{6}{Reweighting coefficient improves robustness against label noise}{equation.3.12}{}}
\newlabel{eq:loss}{{13}{6}{Reweighting coefficient improves robustness against label noise}{equation.3.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Method 3: heuristic approach by relabelling}{6}{subsection.3.6}}
\newlabel{2nd}{{3.6}{6}{Method 3: heuristic approach by relabelling}{subsection.3.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.1}Conditional probability filters samples}{6}{subsubsection.3.6.1}}
\newlabel{2nd2}{{3.6.1}{6}{Conditional probability filters samples}{subsubsection.3.6.1}{}}
\newlabel{eq:filter}{{14}{6}{Conditional probability filters samples}{equation.3.14}{}}
\citation{Walck:1996cca}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.2}Label correction}{7}{subsubsection.3.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Tuning hyperparameters}{7}{subsection.3.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8}Bootstrap constructs confidence intervals and hypothesis tests}{7}{subsection.3.8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.8.1}Bootstrapping percentile confidence intervals}{7}{subsubsection.3.8.1}}
\newlabel{ci}{{3.8.1}{7}{Bootstrapping percentile confidence intervals}{subsubsection.3.8.1}{}}
\newlabel{eq:boot}{{15}{7}{Bootstrapping percentile confidence intervals}{equation.3.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.8.2}Kolmogorov-Smirnov test compares the accuracy of algorithms}{7}{subsubsection.3.8.2}}
\newlabel{sec:ks}{{3.8.2}{7}{Kolmogorov-Smirnov test compares the accuracy of algorithms}{subsubsection.3.8.2}{}}
\newlabel{epdf}{{16}{7}{Kolmogorov-Smirnov test compares the accuracy of algorithms}{equation.3.16}{}}
\newlabel{teststatistic}{{17}{8}{Kolmogorov-Smirnov test compares the accuracy of algorithms}{equation.3.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{8}{section.4}}
\newlabel{result}{{4}{8}{Experiments}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Experiment Setting}{8}{subsection.4.1}}
\@writefile{lpc}{\contentsline {lpcsec}{\numberline {}Chen\ - what do you mean by here? please cross reference}{8}{section*.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces HPC}}{8}{figure.1}}
\newlabel{fig:HPC}{{1}{8}{HPC}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Compare Images}{8}{subsection.4.2}}
\@writefile{lpc}{\contentsline {lpcsec}{\numberline {}Chen\ - cross reference}{8}{section*.3}}
\@writefile{lpc}{\contentsline {lpcsec}{\numberline {}Chen\ - let the figure float. this is the way too small. Perhaps make it $2\times 2$ figures. Also, turn off the axis. You could use the code in my assignment 1 directory.}{9}{section*.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Comparison between original images and processed ones}}{9}{figure.2}}
\newlabel{fig:Compare_Image}{{2}{9}{Comparison between original images and processed ones}{figure.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Mean sd}}{9}{table.1}}
\newlabel{tab:Meansd}{{1}{9}{Mean sd}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Discuss flip rate}{9}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Hayperparameter Tuning}{9}{subsection.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Compare Results}{9}{subsection.4.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1}Expectation Maximisation is the fastest}{9}{subsubsection.4.5.1}}
\citation{liu2016classification}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Hypothesis test}}{10}{table.2}}
\newlabel{tab:HypothesisTest}{{2}{10}{Hypothesis test}{table.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.2}\textsc  {cifar} is more difficult to classify}{10}{subsubsection.4.5.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.3}Heuristic approach is inconsistent}{10}{subsubsection.4.5.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.4}Hypothesis test justifies observations}{10}{subsubsection.4.5.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Discussion}{10}{subsection.4.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Box plots of the accuracy results against running time. {\color  {red}Describe various lines and the dots as well as colours here. } }}{11}{figure.3}}
\newlabel{fig:Boxplot}{{3}{11}{Box plots of the accuracy results against running time. {\color {red}Describe various lines and the dots as well as colours here. }}{figure.3}{}}
\bibstyle{unsrtnat}
\bibdata{reference}
\bibcite{hardle2007applied}{{1}{2007}{{H{\"a}rdle and Simar}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Density function from kernel smoothing}}{12}{figure.4}}
\newlabel{fig:Density}{{4}{12}{Density function from kernel smoothing}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Backup Statements}{12}{subsection.4.7}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{12}{section.5}}
\newlabel{headings}{{5}{12}{Conclusion}{section.5}{}}
\bibcite{Bishop:2006:PRM:1162264}{{2}{2006}{{Bishop}}{{}}}
\bibcite{pmlr-v20-biggio11}{{3}{2011}{{Biggio et~al.}}{{Biggio, Nelson, and Laskov}}}
\bibcite{brodley1996identifying}{{4}{1996}{{Brodley et~al.}}{{Brodley, Friedl, et~al.}}}
\bibcite{liu2016classification}{{5}{2016}{{Liu and Tao}}{{}}}
\bibcite{NIPS2012_4500}{{6}{2012}{{Jin and Wang}}{{}}}
\bibcite{Seeger:2003:PGE:944919.944929}{{7}{2003}{{Seeger}}{{}}}
\bibcite{Cortes1995}{{8}{1995}{{Cortes and Vapnik}}{{}}}
\bibcite{Fernandez-Delgado:2014:WNH:2627435.2697065}{{9}{2014}{{Fern\'{a}ndez-Delgado et~al.}}{{Fern\'{a}ndez-Delgado, Cernadas, Barro, and Amorim}}}
\bibcite{frenay2014classification}{{10}{2014}{{Fr{\'e}nay and Verleysen}}{{}}}
\bibcite{yang2018adasampling}{{11}{2018}{{Yang et~al.}}{{Yang, Ormerod, Liu, Ma, Zomaya, and Yang}}}
\bibcite{Boser:1992:TAO:130385.130401}{{12}{1992}{{Boser et~al.}}{{Boser, Guyon, and Vapnik}}}
\bibcite{hastie01statisticallearning}{{13}{2001}{{Hastie et~al.}}{{Hastie, Tibshirani, and Friedman}}}
\bibcite{jonsson2002support}{{14}{2002}{{Jonsson et~al.}}{{Jonsson, Kittler, Li, and Matas}}}
\bibcite{Platt99probabilisticoutputs}{{15}{1999}{{Platt}}{{}}}
\bibcite{Wu03probabilityestimates}{{16}{2003}{{Wu et~al.}}{{Wu, Lin, and Weng}}}
\bibcite{Walck:1996cca}{{17}{1996}{{Walck}}{{}}}
\ulp@afterend
