\documentclass[12pt]{article} % For LaTeX2e
\usepackage{latex_template,times}
\usepackage{hyperref}
\usepackage{url}

\usepackage{natbib}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{euler}
\usepackage{prettyref}
\usepackage[]{hyperref}
\usepackage{mathtools}
\usepackage{csvsimple}
\usepackage{booktabs}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}
% in dvi it only seems to use urlcolor !!!!
\hypersetup{colorlinks,linkcolor=blue,citecolor=blue,pagecolor=blue,%
            urlcolor=magenta,filecolor=magenta,breaklinks,%
            dvips,bookmarks,bookmarksopen}
%\documentstyle[nips14submit_09,times,art10]{article} % For LaTeX 2.09

%\author{Chen C che5002 480458339, Yutong Cao ycao5602 470347494,***}
\title{Assignment 2}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}
\newcommand{\svm}{\textsc{svm}}
\newcommand{\loss}{\ell}
\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}

\author{%
 \begin{tabular}{rl}
  Tutors: & Zhuozhuo Tu, Liu Liu\\ \\
Group members: & Chen Chen (cche5002) 480458339,\\
& Yutong Cao (ycao5602) 470347494,\\
& Yixiong Fang (yfan5798) 480133344
\end{tabular}
}

\maketitle



\begin{abstract}
This report documents our modifications to the soft-margin support vector machine to improve its performance against class-dependent classification noise where the flip rates are $\rho_0=0.2$ and $\rho_1=0.4$.
\end{abstract}
\tableofcontents
\section{Introduction}
This report documents our modifications to the soft-margin support vector machine~(\svm) to improve its performance against class-dependent classification noise (\textsc{ccn}).

The capability of learning with label noise is crucial for training machine learning models. According to the Law of Large Numbers \citep{hardle2007applied}, the empirical risk converges to the expected risk asymptotically as the sample size approaches infinity. However, classification labels in large data set can be easily corrupted. For example, images  are sometimes labelled manually by employing casual staff with minimal training. In this case, training a classification models using these images requires special treatment that accounts for noisy labels. Section~\ref{method} proposes three such treatments based on \svm\ to increase the accuracy with presence of \textsc{ccn}.

%maybe move to related work
%Usually there is a trade-off between the data complexity and the data quality ({\color{red} reference!}). Weakly supervised learning methods are introduced to handle this kind of problems ({\color{red} reference!}). For example, positive and unlabelled learning and semi-supervised learning are designed to trade data complexity for data quality. They both make use of a small set of correct data to train a model. Also there is learning with noisy labels, on the contrary, trades data quality for data complexity. It learns a model with a large amount of noisy data. In this assignment, we only focused on the latter.

 %For both data sets, the flip rates are given. 
Section~\ref{1st} proposed a learning method by deriving a new loss function using Expectation Maximisation \citep[p.423]{Bishop:2006:PRM:1162264}. This method models the label noise using a Bernoulli distribution, and includes the label noise information into the loss function of \svm. This method is first studied by \citet{pmlr-v20-biggio11} for random classification noise (\textsc{rcn}), and we extended it to \textsc{ccn}. 

Section~\ref{2nd} introduces a heuristic approach based on the work of \citet{brodley1996identifying}. This method follows the heuristic observation that the predicted probability of a sample point with wrong label is usually close to 0.5. In this case, our model is not capable of suggesting a prediction with confidence. We then exclude the potential noisy data points and train the model again with the remaining data which seems to be cleaner. 

Section~\ref{3rd} implements importance reweighting proposed by \citet{liu2016classification}. This method uses a reweighting coefficient to reweight the loss function for each sample point. We fit \svm s with the given noisy data. We then implement cross-validation of \svm\ models to predict the probabilities of classifying each sample, and then use these probabilities to calculate the weightings.

To fairly compare these three approaches of attacking noisy data, all of the three methods implement the same base classification algorithm---\svm. We use \svm\ because it is proved to has a strong generalisation ability \citep{NIPS2012_4500,Seeger:2003:PGE:944919.944929,Cortes1995}, and usually gives high classification accuracy when turned properly \citep{Fernandez-Delgado:2014:WNH:2627435.2697065}. In addition, \svm\ is more susceptible to label noise than many other algorithms \citep{frenay2014classification}, so we can better assess our modification to the original classification algorithm.
%As a result,  it is not considered to be robust to label noise ({\color{red} gives reference})

Section~\ref{result} applies the three methods proposed in Section~\ref{method} to two sets of noisy data with binary labels, both containing $10,000$ images. The first data set is a subset of the fashion-\textsc{mnist} database and the second data set is from the \textsc{cifer} database. For each data set, Section~\ref{result} also compares the simulation results, including accuracy and running times, from the three methods. In addition, we estimate the flip rate~$\rho_0$, $\rho_1$ using the method proposed by \citet{liu2016classification}. 
%We did not use the estimated values in our classification experiments as the true rates are provided. 
Section~\ref{result} also compares our estimation with the true values.

\section{Related work}
Many recent literature discusses the topic of learning with label noise. One popular approach is to use classification algorithms that are proved to be robust to label noise. \citet{frenay2014classification} reported their findings that $0-1$ loss and least-squares loss are robust loss functions to uniform label noise. %compared $179$ classifiers from $17$ families on $121$ data sets. 
They also found the method of bagging is robust against label noise. Bagging detect the contaminated samples by estimating the variability of its base classifier when including and excluding them. %We chose not to use the robust loss functions as the corresponding classification models may not produce satisfying classification accuracy as \textsc{svm}. 
%But we used a bagging-like technique by sampling multiple times and averaging the predicted probabilities to generate better and more stable predictions. 
\citet{frenay2014classification} also discussed filtering methods for learning with label noise. These methods remove mislabelled data before training a final model. Our second model follows this idea by excluding data points with vague predictions. Instead of removing the contaminated candidates directly, \citet{yang2018adasampling} proposed a filter-like method that estimating the probability of mislabelling for each sample. 

These approaches mentioned above do not require noise rates. Although this makes the approaches general, the methods may not be able to handle highly contaminated data set, especially when the noise rates are given. \citet{pmlr-v20-biggio11} applies Expectation Maximisation method to fit data with \textsc{rcn}. This method reformulates the loss function to include noise rate information. The label noise is not usually observed. They use the expected value as an estimation of unobserved labels contaminated by noise. Section~\ref{1st} extends his method to solve problems with \textsc{ccn}. The idea behind this method is straightforward and intuitive, but  simulation results in Section~\ref{result} finds it is less accurate than the method of importance reweighting proposed by \citet{liu2016classification}. \citet{liu2016classification} assigned a weight to each sample according to its probability of being contaminated. These probabilities are estimated from a pre-train model. They also provided an efficient method for estimating the noise rate. However, the need of fitting the model twice makes the method of reweighting slow.

\section{Methods}\label{method}
We use \textsc{svm} with Gaussian kernel as the base classification method for this task because of its generalisation ability.

Let vector~$x_i$ to represent the $i$th image in the dataset. The corresponding true classification labels~$y_i$ of images are corrupted by \textsc{ccn} and the we only observe the contaminated labels~$s_i$.The clean and observed label~$y_i$ and $s_i$ are both binary variables drawn from set~$\left\{-1,1\right\}$.  The nature of \textsc{ccn} implies that class dependent noises~$\epsilon(s_i)$ follows Bernoulli distributions with the mean parameters as either $\rho_0$ or $\rho_1$, depending on the value of label~$s_i$. The observed label~$s_i$ is correct if and only if the noise~$\epsilon(s_i)=0$. For the $i$th image, it is straightforward to verify that
\begin{equation} \label{eq:noise}
y_i=s_i(1-2\epsilon(s_i)).
\end{equation}

\textsc{svm} with Gaussian kernel was first published by \citet{Boser:1992:TAO:130385.130401}. \citet{Cortes1995} proposed an improvement on the original \textsc{svm} with soft-margin  to  avoid over-fitting problem. The \textsc{svm} is to minimise the Hinge loss function
\begin{equation*}
\left[{\frac {1}{n}}\sum _{i=1}^{n}\max \left(0,1-y_{i}(w\cdot x_{i}-b)\right)\right]+\lambda \lVert w\rVert ^{2}.   
\end{equation*}
Here, $w$ is the weighting factor, $b$ is a constant. We classify the $i$th image into category~$1$ or~$-1$ when $w\cdot x_{i}-b\geq1$ or $w\cdot x_{i}-b\leq-1$, respectively. This loss function not only penalises points that misclassified, but also points that are closed to the dividing hyperplane, with a regularisation term~$\lambda \lVert w\rVert ^{2}$. \citet{Fernandez-Delgado:2014:WNH:2627435.2697065} suggested \svm\ is very likely to be one of the most powerful classifiers, by comparing 179 classification algorithms over 121 large data sets. The distances between data points and the dividing hyperplane gives an intuitive estimate of the generalisation ability of the trained \svm\ model \citep{hastie01statisticallearning}. 

we use \svm\ as our classification method as of its strong generalisation ability. In this image classification assignment, we do not observe the true  labels~$y_i$. This section proposes three different approaches to modify ordinary \svm\ to attack label noise problem. However, we do not have access to a test data set with true labels~$(x_i,y_i)$ to verify the generalisation ability of our three different models, which are all trained by noisy data~$(x_i,S_i)$. In \svm , the gap between hyperplane and the training data set provides a natural and `free' metric of its generalisation ability  \citep{hastie01statisticallearning}, and hence use of test data set is not mandatory. Using this geometry factor as well as probably approximately correct learning framework,  \citet{NIPS2012_4500} proved that the  \svm\ models have strong generalisation ability. Further,  \citep{Cortes1995,Seeger:2003:PGE:944919.944929} also shows the strong generalisation ability from different perspectives.

{\color{red}Also comment on the poor robustness and why this is good for the purpose of assignment.}

\subsection{Preprocess}
\subsubsection{Photometric normalisation improves classification performance}
We applied Photometric normalisation suggested by \citet{jonsson2002support} to re-scaled the image data sets to have mean of zero and standard deviation of one. This scaling visually removes the brightness difference among different images, and dramatically improves the performance of Gaussian kernel \svm . This preprocess procedure is mandatory because Gaussian kernel is a radius based kernel, which only performs well when data are on a similar scale \citep{jonsson2002support}. 

\subsubsection{Principle component analysis reduces dimensionality}
For the large \textsc{cifer} data set, we applied principle component analysis (\textsc{pca}) to decrease the dimensionality of the data set from $3072$ to $100$. No \textsc{pca} is applied to the \textsc{mnist} data set because the dimensionality ($784$) is already low comparing with the number of samples ($10,000$) in the data set.

\subsection{The original data set is balanced} \label{sec:1}
Define random variables~$Y$ and $S$ as the true and contaminated binary classification label of a random image vector~$X$, respectively. The assignment instruction states the probabilities~$\rho_0=P(S=1|Y=-1)=0.2$ and $\rho_1=P(S=-1|Y=1)=0.4$.
%, where $S$ are the contaminated classification labels and $Y$ are the true classification labels. 
The contaminated data has $40.0\%$ labels~$S$ as one (i.e. $P(S=1)$). Using this factor and the law of total probability
\begin{equation*}
P(S=1)=P(S=1|Y=1)P(Y=1)+P(S=1|Y=-1)P(Y=-1),
\end{equation*}
An observe label can either be $1$ or $-1$, $P(S=1|Y=1)=1-P(S=-1|Y=1)$,
\begin{equation*}
P(S=1)=\left[1-P(S=-1|Y=1)\right]P(Y=1)+P(S=1|Y=-1)P(Y=-1)
\end{equation*}
Knowing the flip rates~$P(S=-1|Y=1)=0.4$ and $P(S=1|Y=-1)=0.2$
\begin{equation*}
P(S=1)=0.6P(Y=1)+0.2\left[1-P(Y=1)\right]=0.4, \nonumber
\end{equation*}
which implies $P(Y=1)=P(Y=-1)=0.5$. Thus, the original classification problem is balanced. 
In addition, define the Bernoulli random variable~$\epsilon(S)$ with the means $E(\mu(\epsilon)(S=-1))=P(Y=1|S=-1)=0.5\times0.4/0.6=1/3$ and $E(\epsilon(S=1))=P(Y=-1|S=1)=0.5\times0.2/0.4=0.25$. This random variable~$\epsilon$ describe the unobserved random label noise. Hence the expectation
\begin{equation}
    E\epsilon(S)=P(Y=-1|S=1)P(S=1)+P(Y=1|S=-1)P(S=-1)
    %=0.25\times 0.4+1/3\times0.6
    =0.3.\label{eq:exp}
\end{equation}
\subsection{Method 1: Expectation Maximisation}\label{1st}
This section extends the Expectation Maximisation algorithm proposed by \citet{pmlr-v20-biggio11} to improve ordinary \svm\ against labels noises, with mathematical justifications.
%---the given label noise where flip rates~$P(S=1|Y=-1)=0.2$ and~$P(S=-1|Y=1)=0.4$ seems to be marginally different to a random label noise with flip rate~$P(S=1|Y=-1)=P(S=-1|Y=1)=0.3$ for \textsc{svm}.
\subsubsection{Expectation Maximisation derives loss function}
The original algorithm proposed by \citet{pmlr-v20-biggio11} was proposed to study classification problems with label noise where the flip rate $\rho_0=\rho_1$ and we extend it to manage the case dependent label noise where the flip rates can be different.

Recall the dual problem of an \textsc{svm} is to maximise
\begin{equation}
   f(c_{1}\ldots c_{n})=\sum _{i=1}^{n}c_{i}-{\frac {1}{2}}\sum _{i=1}^{n}\sum _{j=1}^{n}y_{i}c_{i}k(x_{i},x_{j})y_{j}c_{j}, \label{eq:dual}
\end{equation}
\begin{math}
{\text{subject to }}\sum _{i=1}^{n}c_{i}y_{i}=0,\,{\text{and }}0\leq c_{i}\leq {\frac {1}{2n\lambda }}\;{\text{for all }}i. 
\end{math} 
Here $y_i$ and $x_i$ are the labels and features of the $i$th image, $c_i$ is the $i$th Lagrangian multiplier, $k(x_i,x_j)$ is the Gaussian kernel product of $x_i$ and $x_j$ whose corresponding kernel is
\begin{math}
\exp(-\gamma\norm{x_i-x_j}).
\end{math} 
Substituting label noise~\eqref{eq:noise} into loss function~\eqref{eq:dual} gives
\begin{equation}
   f(c_{1}\ldots c_{n})=\sum _{i=1}^{n}c_{i}-{\frac {1}{2}}\sum _{i=1}^{n}\sum _{j=1}^{n}S_{i}c_{i}k(x_{i},x_{j})S_{j}c_{j}(1-2\epsilon(S_i))(1-2\epsilon(S_j)). \label{eq:dual2}
\end{equation}
This loss function involves random variables. For a similar  but simpler problem with \textsc{rcn}, \citet{pmlr-v20-biggio11} applied the technique of Expectation Maximisation, which uses the expected value of the loss function as the objective function for optimisation algorithms.

Here, when $i=j$, the expectation~$E(1-2\epsilon(S_i))(1-2\epsilon(S_j))=1-4E\epsilon(S_j)+4E\epsilon(S_j^2)=1$. 
When $i\neq j$, by substituting these expectations~\eqref{eq:exp} from Section~\ref{sec:1}, the expectation~$E(1-2\epsilon(S_i))(1-2\epsilon(S_j))=(1-2E\epsilon(S_i))(1-2E\epsilon(S_j))=0.16$. 

Define kernel correction matrix~$M$ with the $(i,j)$-th entry being $m_{ij}$.The diagonal entries~$m_{ii}=1 $, and the off diagonal entries~$m_{ij}=0.16$ when indexes~$i\neq j$. Using the technique of Expectation Maximisation, the loss function~\eqref{eq:dual2} simplifies to
\begin{equation}
   Ef(c_{1}\ldots c_{n})=\sum _{i=1}^{n}c_{i}-{\frac {1}{2}}\sum _{i=1}^{n}\sum _{j=1}^{n}S_{i}c_{i}k(x_{i},x_{j})S_{j}c_{j}m_{ij}, \label{eq:dual3}
\end{equation}
Comparing this loss function and the ordinary loss function of \svm \eqref{eq:dual}, the only difference is to replace the kernel matrix~$K$ with our new proposed matrix~$Q:=K\circ M$, where $\circ$ denote the Hadamard product \citep{hastie01statisticallearning}.

%\subsubsection{Additional regularisation}


%This soft-margin \textsc{svm} is sub-optimal for our problem. We have a large set of data ($10,000$) comparing with the number of features ($784$). Hence, we build a modified \textsc{svm} that aims to minimise the following Hinge loss
%\begin{equation}
%\left[{\frac {1}{n}}\sum _{i=1}^{n}\max \left(0,10-y_{i}(w\cdot x_{i}-b)\right)\right]+\lambda \lVert %w\rVert ^{2}.   \label{eq:pri}
%\end{equation}
%The modified constant~$10$ requires the predictor~$w\cdot x_{i}-b$ to be as extreme as possible, i.e., it penalises wrongly classified samples. Moreover, it even penalises correctly classified samples with small gaps between data points and the dividing hyper-plane being small. 
%Define $\zeta _{i}:=\max \left(0,10-y_{i}(w\cdot x_{i}-b)\right)$. The prime problem of Hinge loss~\eqref{eq:pri} becomes a minimisation of
%\begin{equation}
%{\frac {1}{n}}\sum _{i=1}^{n}\zeta _{i}+\lambda \|w\|^{2}
%{\text{ subject to }}y_{i}(w\cdot x_{i}-b)\geq 10-\zeta _{i}\,{\text{ and }}\,\zeta _{i}\geq 0,\,{\text{for all }}i. \label{eq:pri2}
%\end{equation} 
%The modification is inspired by observing that the regularisation parameter~$\lambda$ has a negligible impact on the classification results for this problem. Hence we have more than enough data to train this complex model without over fitting.

%The modified \textsc{svm} aims to make the algorithm more robust to label noise, even though it may enlarge the generalisation error. Nevertheless, the large data set will assure us the generalisation error is within a reasonable magnitude.
%The parameters~$c_i$ are Lagrangian multipliers that enforcing the condition~$y_{i}(w\cdot x_{i}-b)\geq 10-\zeta _{i}$ in prime problem~\eqref{eq:pri2}.

%With this modification, the dual problem~\eqref{eq:dual3} of the loss function~\eqref{eq:pri} becomes
%\begin{equation*}
%   Ef(c_{1}\ldots c_{n})=10\sum _{i=1}^{n}c_{i}-{\frac {1}{2}}\sum _{i=1}^{n}\sum %_{j=1}^{n}S_{i}c_{i}k(x_{i},x_{j})S_{j}c_{j}m_{ij}. \label{eq:dual3}
%\end{equation*}
%From the dual prospective, we are weakening the contributions of the contaminated labels~$S_i$, hence making the algorithm more robust.



This method gives us an accuracy of $94.6\%$ on the testing data.

\subsection{Method 2: heuristic approach}\label{2nd}
Method 2 still implement \textsc{svm}. We chose \textsc{svm} because classification algorithms with Hinge loss, including \textsc{svm}, is robust against random classification label noise. Our label noise is class dependent. However, experiment shows that \textsc{svm} is still robust against it.
%\subsubsection{Hinge loss is robust against label noise}

\subsubsection{Select samples}
Ordinary \textsc{svm} only gives a classification without revealing a probability that indicates the confidence of classification. \citet{Wu03probabilityestimates} proposed a five-fold cross-validation method to calculate the classification probabilities~$P(Y=1|X)$ for \textsc{svm}. 
Using this method, we calculated the probability~$P(Y=1|X)$ with label noise by an \textsc{svm} with Gaussian kernel. We have $10,000$ samples. We only use those with largest and smallest $P(Y=1|X)$ (first $1/3$ and last $1/3$), because intuitively the contaminated samples are more likely to have a probability~$P(Y=1|X)$ close to $0.5$ and the error rate $P(\epsilon=1)=0.3\approx 1/3$. %A $3\%$ margin was left because classification errors must exist.
\subsubsection{Label correction}
We relabel the $1/3$ of the samples with highest fitted probability~$P(Y=1|X)$ as $1$ and the $1/3$ samples with the smallest fitted probability~$P(Y=1|X)$ as $-1$. This step is important because section~\ref{sec:1} shows that the original data set is balanced ($P(Y=1)=P(Y=-1)=0.5$). 

Training our \textsc{svm} with Gaussian Kernel again with this subset of relabeled data gives our second model.

This method gives us an accuracy of $95.0\%$ on the testing data.
%\subsubsection{Hinge loss if robust against label noise}
\subsection{Method 3: Importance Reweighting} \label{3rd}
This section applies theorems proved by \citet{liu2016classification} to construct a weighted loss that includes noise information~$\rho_0$ and $\rho_1$. Define $D$ to be the probability density function of the clean data~$(X,Y)$ and $D_\rho$ to be that of contaminated data~$(X,S)$. \\{\color{red} ATTENDTION! I used $P$ in previous sections. Either use $P_D$ in all probability notations in this report or none of them. Also define $f$ which I have no clue what it is. Note that I have already occupied the letter $f$. Use something else if this is not the same $f$. Alternative change my previous letters $f$. Either way, Be consistent}.
\citet{liu2016classification} construct a reweighting coefficient vector~
\begin{equation}
\beta(X,Y,S)=\frac{P_D(Y|X)}{P_{D_\rho}(S|X)}. \label{beta} 
\end{equation}
This reweighting coefficient~$\beta(X,Y,S)$ is then used to estimate the expected risk~$R_{\loss,D}(f)$ in the with the empirical risk $R_{\loss,D_\rho}(f)$
\begin{equation*}
R_{\loss,D}(f) = R_{\beta \loss,D_\rho}(f). 
\end{equation*}
This equation allows us to estimate the true loss function~$R_{\loss,D}(f)$ without knowing the true labels~$Y$. 
%in  to represent the expected risk if we can find the value of $\beta$
%where $D$ is the distribution of  and $D_\rho$ is the distribution of .
%The transformation deducted as follows:  
\\{\color{red} either use $\mathbb E$ for all expectation all none of them please fix}\\%
%\begin{eqnarray*}
%R_{l,D}(f) &=& \mathbb{E}_{(X,Y)\sim D}[l(f(X),Y)]\\
%           &=& \sum_{y}\int{P_D(X,Y=y)l(f(X),Y=y)}dX \\
%           &=& \sum_{y}\int{P_{D_\rho}(X,S=y)\frac{P_D(X,Y=y)}{P_{D_\rho}(X,S=y)}l(f(X),Y=y)}dX\\
%           &=& \mathbb{E}_{(X,S)\sim D_\rho}[\frac{P_D(X,Y=y)}{P_{D_\rho}(X,S=y)}l(f(X),S)]\\
%           &=& \mathbb{E}_{(X,S)\sim D_\rho}
%              [\beta l(f(X),S)] \\
%           &=& R_{\beta l,D_\rho}(f)
%\end{eqnarray*}
%Where $\beta=\frac{P_D(X,Y)}{P_{D_\rho}(X,S)}=\frac{P_D(Y|X)}{P_{D_\rho}(S|X)}$ as the distribution of $X$ does not change between $D_\rho$ and $D$.
%Now we can . 
%Although we can make an approximation for $D_\rho$ using the given data, we can not approximate the distribution $D$ directly. 
%We need to represent $P_D(Y|X)$ using $P_{D_\rho}(S|X)$ and the noise rates.
%\begin{equation}
%    \begin{aligned}
%    P(S=y|X) &= P(Y=y,S=y|X)+P(Y=-y,S=y|X)\\
%               &= P(S=y|X,Y=y)P(Y=y|X)
%                  +P(S=y|X,Y=-y)P(Y=-y|X)\\
%               &= (1-\rho_{y})P(Y=y|X)+\rho_{-y}[1-P(Y=y|X)]\\
%               &= (1-\rho_{y}-\rho{-y})P(Y=y|X)+\rho_{-y}
%    \end{aligned}
%\end{equation}
With some reasonable assumptions ({\color{red} what are the assumptions}), \citet{liu2016classification} also derived the distribution of the unobserved  true label using the observed label~$S$, the flip rates~$\rho_{0}$ and $\rho_{1}$
\begin{equation}
    P_D(Y=y|X)=\frac{P_{D_\rho}(S=y|X)-\rho_{1-y}}{1-\rho_{y}-\rho_{1-y}}\text{ where }y\in \left\{0,1\right\}.
\end{equation}
Substitute this estimation into the weighting coefficient~\eqref{beta}
\begin{equation}
    \beta=\frac{P_{D_\rho}(S=y|X)-\rho_{1-y}}{(1-\rho_{y}-\rho_{1-y})P_{D_\rho}(S=y|X)}\text{ where }y\in \left\{0,1\right\}.
\end{equation}
Then the problem is reduced to estimating the conditional probability~$P_{D_\rho}(S=y|X)$.
\citet{liu2016classification} provided three methods. 
We choose to use the density ratio method for estimating $P_{D_\rho}(S=y|X)$. Firstly, Remark 1 given by \citet{liu2016classification} indicates the probabilistic method `does not perform well'. Secondly, our data sets are high dimensional, so the kernel density estimation method would suffer from the curse of dimensionality. We use ***(refer to papers given on the github page of densratio package)

\subsection{Flip rates estimation methods}\label{method2}
We apply techniques proposed by \citet{liu2016classification} to estimate the flip rates~$\rho_0$ and $\rho_1$. The technique consists of two steps---firstly, we estimate probability~$P_{D_\rho}(S=y|X)$; secondly, we estimate the flip rates~$\rho_0$ and $\rho_1$ using the probability~$P_{D_\rho}(S=y|X)$.

****
\subsection{Tuning hyperparameters}
The Kernel parameter for Gaussian Kernel~$\gamma$ is chosen to maximise the variance of Kernel matrix~$K(x_i,x_j)$ over all $i,j$. The regularisation parameter is chosen by grid search. The model seems to be insensitive to the regularisation parameter.

\subsection{Bootstrap constructs confidence intervals and hypothesis tests}\label{ci}
The assignment instruction asks us to compare the accuracy, denoted as $A$, of the proposed label noise robust algorithms. To systematically compare the metrics, we construct an $95\%$ confidence interval for $A$ by bootstrapping percentile confidence interval. The idea of bootstrapping  is straightforward---we resample a subset of $8$ samples among the sample space of $16$ simulation results and calculate the mean. We repeat this process $1000$ times. The $2.5\%$ and $97.5\%$ percentiles of the $1000$ re-sampled means are then the bootstrapping percentile confidence interval
\begin{equation}
({A}^*_{2.5}, {A}^*_{97.5}), \label{eq:boot}
\end{equation}
where $A^*_{\alpha}$ is the $\alpha$ percentile of the bootstrapped distribution from our sample space with $16$ accuracy result from Monte-Carlo simulations.

Bootstrapping does not require the sample space follows specific distributions. We apply this nonparametric method to construct confidence interval here because we do not know about the exact distributions of accuracy~$A$.

\section{Statistical method compares the robustness of algorithms}
We implement the Kolmogorov-Smirnov test to test the hypothesis that the algorithms proposed in Section~\ref{method} have different robustness.  Again, Kolmogorov-Smirnov test is distribution free, so we do not need to know the distributions of the evaluation metrics.

Let $A_{ij}$ denote the accuracy generated from our {$i$}th algorithm from the $j$th Monte-Carlo simulation. Define the empirical distribution of accuracy results generated by algorithm~$i$ as
\begin{equation}\label{epdf}
  \hat{F}_{i}(x)=\frac{1}{n}\sum_{j=1}^{16}1_{A_{iJ} \leq x}.
\end{equation}
The test statistic is the supremum among the differences of the empirical distribution generated using definition~\eqref{epdf} \citep{Walck:1996cca}
\begin{equation}\label{teststatistic}
D=\sup _{x}\left|F_{i_1}(x)-F_{i_2}(x)\right|.
\end{equation}
We compare the test statistics~$D$ with the critical value of $0.433$, which corresponds to $16$ samples and a $95\%$ of confidence level. We reject the null hypotheses that the two algorithms produce similar Accuracy~$A$ with $95\%$ confidence level if the test statistics~$D>0.43$. The technique is also applied to perform one tail test to test whether one algorithm is more accurate than the other.
\section{Experiments and discussions}\label{result}

\begin{table}
\centering
    \scalebox{0.9}{
	\begin{tabular}{lllll}
\toprule
Data & Null Hypothesis ($H_0$) & $D$ & P-value & Reject $H_0$\\
\midrule
 & Relabelling algorithm is no more accurate than Expectation Maximisation.  & 0.625 & 0.0019 & Reject\\
 
 \textsc{mnist} & Expectation Maximisation algorithm is as accurate as Reweighting. & 0.3125 & 0.4154 & Fail to reject\\
 
  & Reweighting algorithm is as accurate as relabelling. & 0.3125 & 0.4154 & Fail to reject\\
\bottomrule
   & Expectation Maximisation algorithm is no more accurate than relabelling. & 0.5 & 0.0183 & Reject\\

 \textsc{cifar}  & Reweighting algorithm is no more accurate than Expectation Maximisation. & 0.6875 & 0.0005 & Reject\\

  & Reweighting algorithm is no more accurate than relabelling.  & 0.6875 & 0.0005 & Reject\\
\hline 
\end{tabular} }
	\caption{Hypothesis test}
	\label{tab:HypothesisTest}
\end{table}

\begin{table}
	\caption{Mean sd}
	\label{tab:Meansd}
% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
\centering
\begin{tabular}{@{}lll@{}}
\toprule
Mean  & Standard deviation & Confidence interval \\ \midrule
0.938 & 0.003              & (0.936,0.939)       \\
0.942 & 0.003              & (0.941,0.944)       \\
0.94  & 0.003              & (0.939,0.942)       \\
0.835 & 0.004              & (0.833.0.837)       \\
0.832 & 0.008              & (0.829,0.836)       \\
0.844 & 0.005              & (0.841,0.846)       \\ \bottomrule
\end{tabular}

\end{table}



\begin{figure}    
	\includegraphics[scale=0.9]{boxplot.pdf}
	\caption{Boxplot}
	\label{fig:Boxplot}
\end{figure}

\begin{figure}    
	\includegraphics[scale=0.9]{histo.pdf}
	\caption{Density function from kernel smoothing}
	\label{fig:Density function from kernel smoothing}
\end{figure}

scatter plot of time vs. accuracy
histogram of accuracy
mean, sd table

Please pay special attention to the instructions in section \ref{others}
regarding figures, tables, acknowledgments, and references.

\section{Conclusion}
\label{headings}



\bibliographystyle{unsrtnat}
\bibliography{reference}

\end{document}
