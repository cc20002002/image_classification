\documentclass[12pt]{article} % For LaTeX2e
\usepackage{latex_template,times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{bigints}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{euler}
\usepackage{prettyref}
\usepackage[]{hyperref}
\usepackage{mathtools}
\usepackage{csvsimple}
\usepackage{booktabs}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}
% in dvi it only seems to use urlcolor !!!!
\hypersetup{colorlinks,linkcolor=blue,citecolor=blue,pagecolor=blue,%
            urlcolor=magenta,filecolor=magenta,breaklinks,%
            dvips,bookmarks,bookmarksopen}
%\documentstyle[nips14submit_09,times,art10]{article} % For LaTeX 2.09

%\author{Chen C che5002 480458339, Yutong Cao ycao5602 470347494,***}
\title{Assignment 2}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}
\newcommand{\svm}{\textsc{svm}}
\newcommand{\loss}{\ell}
\newcommand{\rhoo}{\rho_{+1}}
\newcommand{\rhoz}{\rho_{-1}}
\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}

\author{%
 \begin{tabular}{rl}
  Tutors:& Nicholas James, Zhuozhuo Tu, Liu Liu\\ \\
Group members: & Chen Chen (cche5002) 480458339,\\
& Yutong Cao (ycao5602) 470347494,\\
& Yixiong Fang (yfan5798) 480133344
\end{tabular}
}

\maketitle



\begin{abstract}
This report documents our modifications to the soft-margin support vector machine to improve its performance against class-dependent classification noise where the flip rates are $\rho_0=0.2$ and $\rho_1=0.4$.
\end{abstract}
\tableofcontents
\section{Introduction}
This report documents our modifications to the soft-margin support vector machine~(\svm) to improve its performance against class-dependent classification noise (\textsc{ccn}).

The capability of learning with label noise is crucial for training machine learning models. According to the Law of Large Numbers \citep{hardle2007applied}, the empirical risk converges to the expected risk asymptotically as the sample size approaches infinity. However, classification labels in large data set can be easily corrupted. For example, images  are sometimes labelled manually by employing casual staff with minimal training. In this case, training a classification models using these images requires special treatment that accounts for noisy labels. Section~\ref{method} proposes three such treatments based on \svm\ to increase the accuracy with presence of \textsc{ccn}.

%maybe move to related work
%Usually there is a trade-off between the data complexity and the data quality ({\color{red} reference!}). Weakly supervised learning methods are introduced to handle this kind of problems ({\color{red} reference!}). For example, positive and unlabelled learning and semi-supervised learning are designed to trade data complexity for data quality. They both make use of a small set of correct data to train a model. Also there is learning with noisy labels, on the contrary, trades data quality for data complexity. It learns a model with a large amount of noisy data. In this assignment, we only focused on the latter.

 %For both data sets, the flip rates are given. 
Section~\ref{1st} proposed a learning method by deriving a new loss function using Expectation Maximisation \citep[p.423]{Bishop:2006:PRM:1162264}. This method models the label noise using a Bernoulli distribution, and includes the label noise information into the loss function of \svm. This method is first studied by \citet{pmlr-v20-biggio11} for random classification noise (\textsc{rcn}), and we extended it to \textsc{ccn}. 

Section~\ref{3rd} implements importance reweighting proposed by \citet{liu2016classification}. This method uses a reweighting coefficient to reweight the loss function for each sample point. We fit \svm s with the given noisy data. We then implement cross-validation of \svm\ models to predict the probabilities of classifying each sample, and then use these probabilities to calculate the weightings.

Section~\ref{2nd} introduces a filtering approach based on the work of \citet{brodley1996identifying}. This method follows the heuristic observation that the predicted probability of a sample point with wrong label is usually close to 0.5, where our model is not able to classify confidently. In the meanwhile, the predicted classification result of contaminated label is likely to be different from the observed label.  We then exclude the potential contaminated data points and train the model again with the remaining data which seems to be cleaner. 

To fairly compare these three approaches of attacking noisy data, all of the three methods implement the same base classification algorithm---\svm. We use \svm\ because it is proved to has a strong generalisation ability \citep{NIPS2012_4500,Seeger:2003:PGE:944919.944929,Cortes1995}, and usually gives high classification accuracy when turned properly \citep{Fernandez-Delgado:2014:WNH:2627435.2697065}. In addition, \svm\ is more susceptible to label noise than many other algorithms \citep{frenay2014classification}, so we can better assess our modification to the original classification algorithm.
%As a result,  it is not considered to be robust to label noise ({\color{red} gives reference})

Section~\ref{result} applies the three methods proposed in Section~\ref{method} to two sets of noisy data with binary labels, both containing $10,000$ images. The first data set is a subset of the fashion-\textsc{mnist} database and the second data set is from the \textsc{cifer} database. For each data set, Section~\ref{result} also compares the simulation results, including accuracy and running times, from the three methods. In addition, we estimate the flip rate~$\rho_0$, $\rho_1$ using the method proposed by \citet{liu2016classification}. 
%We did not use the estimated values in our classification experiments as the true rates are provided. 
Section~\ref{result} also compares our estimation with the true values.

\section{Related work}
Many recent literature discusses the topic of learning with label noise. One popular approach is to use classification algorithms that are proved to be robust to label noise. \citet{frenay2014classification} reported their findings that $0-1$ loss and least-squares loss are robust loss functions to uniform label noise. %compared $179$ classifiers from $17$ families on $121$ data sets. 
They also found the method of bagging is robust against label noise. Bagging detect the contaminated samples by estimating the variability of its base classifier when including and excluding them. %We chose not to use the robust loss functions as the corresponding classification models may not produce satisfying classification accuracy as \textsc{svm}. 
%But we used a bagging-like technique by sampling multiple times and averaging the predicted probabilities to generate better and more stable predictions. 
\citet{frenay2014classification} also discussed filtering methods for learning with label noise. These methods remove mislabelled data before training a final model. Our second model follows this idea by excluding data points with vague predictions. Instead of removing the contaminated candidates directly, \citet{yang2018adasampling} proposed a filter-like method that estimating the probability of mislabelling for each sample. 

These approaches mentioned above do not require noise rates. Although this makes the approaches general, the methods may not be able to handle highly contaminated data set, especially when the noise rates are given. \citet{pmlr-v20-biggio11} applies Expectation Maximisation method to fit data with \textsc{rcn}. This method reformulates the loss function to include noise rate information. The label noise is not usually observed. They use the expected value as an estimation of unobserved labels contaminated by noise. Section~\ref{1st} extends his method to solve problems with \textsc{ccn}. The idea behind this method is straightforward and intuitive, but  simulation results in Section~\ref{result} finds it is less accurate than the method of importance reweighting proposed by \citet{liu2016classification}. \citet{liu2016classification} assigned a weight to each sample according to its probability of being contaminated. These probabilities are estimated from a pre-train model. They also provided an efficient method for estimating the noise rate. However, the need of fitting the model twice makes the method of reweighting slow.

\section{Methods}\label{method}
We use \textsc{svm} with Gaussian kernel as the base classification method for this task because of its generalisation ability.

Let vector~$x_i$ to represent the $i$th image in the dataset. The corresponding true classification labels~$y_i$ of images are corrupted by \textsc{ccn} and the we only observe the contaminated labels~$s_i$.The clean and observed label~$y_i$ and $s_i$ are both binary variables drawn from set~$\left\{-1,1\right\}$.  The nature of \textsc{ccn} implies that class dependent noises~$\epsilon(s_i)$ follows Bernoulli distributions with the mean parameters as either $\rho_0$ or $\rho_1$, depending on the value of label~$s_i$. The observed label~$s_i$ is correct if and only if the noise~$\epsilon(s_i)=0$. For the $i$th image, it is straightforward to verify that
\begin{equation} \label{eq:noise}
y_i=s_i(1-2\epsilon(s_i)).
\end{equation}

\textsc{svm} with Gaussian kernel was first published by \citet{Boser:1992:TAO:130385.130401}. 
\citet{Cortes1995} proposed an improvement on the original \textsc{svm} with soft-margin  to  avoid over-fitting problem. The \textsc{svm} is to minimise the Hinge loss function
\begin{equation*}
\left[{\frac {1}{n}}\sum _{i=1}^{n}\max \left(0,1-y_{i}(w\cdot x_{i}-b)\right)\right]+\lambda \lVert w\rVert ^{2}.   
\end{equation*}
Here, $w$ is the weighting factor, $b$ is a constant. We classify the $i$th image into category~$1$ or~$-1$ when $w\cdot x_{i}-b\geq1$ or $w\cdot x_{i}-b\leq-1$, respectively. This loss function not only penalises points that misclassified, but also points that are closed to the dividing hyperplane, with a regularisation term~$\lambda \lVert w\rVert ^{2}$. The decision function of \svm\ is
\begin{equation}\label{eq:decision}
 g(x_{i})=\text{sign}(w\cdot x_{i}-b).
\end{equation}

\citet{Fernandez-Delgado:2014:WNH:2627435.2697065} suggested \svm\ is very likely to be one of the most powerful classifiers, by comparing 179 classification algorithms over 121 large data sets. The distances between data points and the dividing hyperplane gives an intuitive estimate of the generalisation ability of the trained \svm\ model \citep{hastie01statisticallearning}. 

we use \svm\ as our classification method as of its strong generalisation ability. In this image classification assignment, we do not observe the true  labels~$y_i$. This section proposes three different approaches to modify ordinary \svm\ to attack label noise problem. However, we do not have access to a test data set with true labels~$(x_i,y_i)$ to verify the generalisation ability of our three different models, which are all trained by noisy data~$(x_i,S_i)$. In \svm , the gap between hyperplane and the training data set provides a natural and `free' metric of its generalisation ability  \citep{hastie01statisticallearning}, and hence use of test data set is not mandatory. Using this geometry factor as well as probably approximately correct learning framework,  \citet{NIPS2012_4500} proved that the  \svm\ models have strong generalisation ability. Further,  \citep{Cortes1995,Seeger:2003:PGE:944919.944929} also shows the strong generalisation ability from different perspectives.

{\color{red} you might make a mistake on the reference. I changed it from \citet{Fernandez-Delgado:2014:WNH:2627435.2697065} to \citep{frenay2014classification}. please cross check for me}

The other reason of implementing \svm\ as the base algorithm is that the hinge loss function makes \svm\ not robust against label noise \citep{frenay2014classification}. Nevertheless, our proposed modifications in Sections~\ref{1st}, \ref{3rd} and~\ref{2nd} give accurate classification results as shown in Section~\ref{result}. If we implement a robust algorithm, e.g. deep neural networks, then one could argue that the flip rates had minimal impact on the classification result anyway. Hence whether our methods perform well would become a mystery.

%As we are not focusing on the effect of robust classification methods on learning with label noise. Using hinge loss should remove this effect and let us focus on the label noise methods we use instead of the natural robust property of certain loss functions.

\subsection{Preprocess}\label{preproc}
\subsubsection{Photometric normalisation improves classification performance}
We applied Photometric normalisation suggested by \citet{jonsson2002support} to re-scaled the image data sets to have mean of zero and standard deviation of one. This scaling visually removes the brightness difference among different images, and dramatically improves the performance of Gaussian kernel \svm . This preprocess procedure is mandatory because Gaussian kernel is a radius based kernel, which only performs well when data are on a similar scale \citep{jonsson2002support}. 

\subsubsection{Principle component analysis reduces dimensionality}
For the large \textsc{cifer} data set, we applied principle component analysis (\textsc{pca}) to decrease the dimensionality of the data set from $3072$ to $100$. Although the dimensionality is reduced by $97\%$, the remaining $3\%$ features explains more than $85\%$ of the variance in the data set. 

When fitting our models in Sections~\ref{1st}, \ref{3rd} and~\ref{2nd}, no \textsc{pca} is applied to the \textsc{mnist} data set because the dimensionality ($784$) is already low comparing with the number of samples ($10,000$) in the data set. Nevertheless, when estimating the flip rates~$\rho_0$ and~$\rho_1$ in Section~\ref{method2}, we applied \textsc{pca} to decrease the number of features of \textsc{mnist} data set to $50$.

\subsection{The original data set is balanced} \label{sec:1}
Define random variables~$Y$ and $S$ as the true and contaminated binary classification label of a random image vector~$X$, respectively. The assignment instruction states the probabilities~$\rho_0=P(S=1|Y=-1)=0.2$ and $\rho_1=P(S=-1|Y=1)=0.4$.
%, where $S$ are the contaminated classification labels and $Y$ are the true classification labels. 
The contaminated data has $40.0\%$ labels~$S$ as one (i.e. $P(S=1)$). Using this factor and the law of total probability
\begin{equation*}
P(S=1)=P(S=1|Y=1)P(Y=1)+P(S=1|Y=-1)P(Y=-1),
\end{equation*}
An observe label can either be $1$ or $-1$, $P(S=1|Y=1)=1-P(S=-1|Y=1)$,
\begin{equation*}
P(S=1)=\left[1-P(S=-1|Y=1)\right]P(Y=1)+P(S=1|Y=-1)P(Y=-1)
\end{equation*}
Knowing the flip rates~$P(S=-1|Y=1)=0.4$ and $P(S=1|Y=-1)=0.2$
\begin{equation}
P(S=1)=0.6P(Y=1)+0.2\left[1-P(Y=1)\right]=0.4, \label{eq:ps}
\end{equation}
which implies $P(Y=1)=P(Y=-1)=0.5$. Thus, the original classification problem is balanced. 
In addition, define the Bernoulli random variable~$\epsilon(S)$ with the means $E(\mu(\epsilon)(S=-1))=P(Y=1|S=-1)=0.5\times0.4/0.6=1/3$ and $E(\epsilon(S=1))=P(Y=-1|S=1)=0.5\times0.2/0.4=0.25$. This random variable~$\epsilon$ describe the unobserved random label noise. Hence the expectation
\begin{equation}
    E\epsilon(S)=P(Y=-1|S=1)P(S=1)+P(Y=1|S=-1)P(S=-1)
    %=0.25\times 0.4+1/3\times0.6
    =0.3.\label{eq:exp}
\end{equation}

\subsection{Flip rates estimation}\label{method2}
We apply techniques proposed by \citet{liu2016classification} to estimate the flip rates~$\rho_0$ and $\rho_1$. The technique consists of two steps---firstly, we estimate probability~$P_{D_\rho}(S|X)$; secondly, we estimate the flip rates~$\rho_0$ and $\rho_1$ using the probability~$P_{D_\rho}(S|X)$. 



\subsubsection{Density ratio method estimates conditional probability}\label{method22}
Bayesian formula expands the conditional probability~$P_{D_\rho}(S=s|X)$ to
\begin{equation}
   P_{D_\rho}(S=s|X)=\frac{P_{D_\rho}(X|S=s)P_{D_\rho}(S=s)}{P_{D_\rho}(X)}.\label{eq:baye}
\end{equation}
Here the probability~$P_{D_\rho}(S=s)$ is given by equation~\eqref{eq:ps}. We use the density ratio method proposed by \citet{DBLP:journals/jmlr/KanamoriHS09} to estimate the ratio~${P_{D_\rho}(X|S=s)}/{P_{D_\rho}(X)}$.

Define a Gaussian Kernel 
\begin{equation}\label{eq:gauss}
k(x_i,x_j)=\exp(-\gamma\norm{x_i-x_j}).
\end{equation} 
Then the set~$\{k(X,x_j) \}_j$ forms the basis function for the probability space of ${P_{D_\rho}(X|S=s)}/{P_{D_\rho}(X)}$. Hence we can model the probability by a linear combination of the basis functions
\begin{equation*}
   \frac{P_{D_\rho}(X|S=s)}{P_{D_\rho}(X)}=\sum_j \alpha_{sj} k(X,x_j) \text{ where }\alpha_{sj}>0.%\label{eq:baye2}
\end{equation*}
To compute coefficients~$\alpha_{sj}$, we treat the centres~$x_j$ and the number of basis functions as hyperparameters and minimises the objective function
\begin{equation*}
  \min_\alpha \bigintss \left(\frac{P_{D_\rho}(X|S=s)}{P_{D_\rho}(X)}-\sum_j \alpha_{sj} k(X,x_j)\right)^2P_{D_\rho}(X)dx \text{ where }\alpha_{sj}>0.
\end{equation*}
Treating terms without coefficients~$\alpha_{sj}$ as constants and applying Monte Carlo to transform the integration into a summation, this objective function further simplifies to a constrained quadratic programming problem about coefficients~$\alpha_{sj}$. Solving this quadratic programming problem gives coefficients~$\alpha_{sj}$, and hence an approximation of the ratio~${P_{D_\rho}(X|S=s)}/{P_{D_\rho}(X)}$. Substituting this ratio into Bayesian formula~\eqref{eq:baye} gives required conditional probability~$P_{D_\rho}(S=s|X)$.

The advantage of the density ratio method is to avoid estimating probabilities~${P_{D_\rho}(X|S=s)}$ and~${P_{D_\rho}(X)}$. Estimating these are usually difficult for high dimensional data~$X$, due to curse of dimensionality. 


\subsubsection{Estimate flip rates}\label{method23}
Theorem~4 proposed by \citet{liu2016classification} estimates the flips rates using the global minimum of conditional probability~~$P_{D_\rho}(S=s|X)$ computed in Section~\ref{method22}
\begin{equation*}\label{eq:fliprate}
\rho_s=\min _X P_{D_\rho}(S=s|X).
\end{equation*}

As our sample size is large ($10,000$), the minimal probability of the samples approximates the global minimum well. 

The method proposed here requires tuning a few hyperparameters by grid search. Thus, later sections do not use this density ratio method for the speed of our algorithms.  
In addition, when numerically computing these flip rates, we only use the data set \textsc{mnist}. This data set is much smaller comparing with \textsc{cifar}, and hence allows us to grid search the best hyperparameter faster. To further avoid over fitting, we applied \textsc{pca} to decreases the number of features to $50$ when estimating flip rates.

As the true flips rates~$\rho_0$ and $\rho_1$ are given, here and after, we use the true flip rates~$\rho_0=0.2$ and $\rho_1=0.4$ in Sections~\ref{1st}, \ref{3rd} and~\ref{2nd}.


\subsection{Method 1: Expectation Maximisation}\label{1st}
This section extends the Expectation Maximisation algorithm proposed by \citet{pmlr-v20-biggio11} to improve ordinary \svm\ against labels noises, with mathematical justifications.
%---the given label noise where flip rates~$P(S=1|Y=-1)=0.2$ and~$P(S=-1|Y=1)=0.4$ seems to be marginally different to a random label noise with flip rate~$P(S=1|Y=-1)=P(S=-1|Y=1)=0.3$ for \textsc{svm}.
\subsubsection{Expectation Maximisation derives loss function}
The original algorithm proposed by \citet{pmlr-v20-biggio11} was proposed to study classification problems with label noise where the flip rate $\rho_0=\rho_1$ and we extend it to manage the case dependent label noise where the flip rates can be different.

Recall the dual problem of an \textsc{svm} is to maximise
\begin{equation}
   f(c_{1}\ldots c_{n})=\sum _{i=1}^{n}c_{i}-{\frac {1}{2}}\sum _{i=1}^{n}\sum _{j=1}^{n}y_{i}c_{i}k(x_{i},x_{j})y_{j}c_{j}, \label{eq:dual}
\end{equation}
\begin{math}
{\text{subject to }}\sum _{i=1}^{n}c_{i}y_{i}=0,\,{\text{and }}0\leq c_{i}\leq {\frac {1}{2n\lambda }}\;{\text{for all }}i. 
\end{math} 
Here $y_i$ and $x_i$ are the labels and features of the $i$th image, $c_i$ is the $i$th Lagrangian multiplier, $k(x_i,x_j)$ is the Gaussian Kernel product~\eqref{eq:gauss} of vectors~$x_i$ and~$x_j$.

Substituting label noise~\eqref{eq:noise} into loss function~\eqref{eq:dual} gives
\begin{equation}
   f(c_{1}\ldots c_{n})=\sum _{i=1}^{n}c_{i}-{\frac {1}{2}}\sum _{i=1}^{n}\sum _{j=1}^{n}S_{i}c_{i}k(x_{i},x_{j})S_{j}c_{j}(1-2\epsilon(S_i))(1-2\epsilon(S_j)). \label{eq:dual2}
\end{equation}
This loss function involves random variables. For a similar  but simpler problem with \textsc{rcn}, \citet{pmlr-v20-biggio11} applied the technique of Expectation Maximisation, which uses the expected value of the loss function as the objective function for optimisation algorithms.

Here, when $i=j$, the expectation~$E(1-2\epsilon(S_i))(1-2\epsilon(S_j))=1-4E\epsilon(S_j)+4E\epsilon(S_j^2)=1$. 
When $i\neq j$, by substituting these expectations~\eqref{eq:exp} from Section~\ref{sec:1}, the expectation~$E(1-2\epsilon(S_i))(1-2\epsilon(S_j))=(1-2E\epsilon(S_i))(1-2E\epsilon(S_j))=0.16$. 

Define kernel correction matrix~$M$ with the $(i,j)$-th entry being $m_{ij}$.The diagonal entries~$m_{ii}=1 $, and the off diagonal entries~$m_{ij}=0.16$ when indexes~$i\neq j$. Taking the expected values of the loss function~\eqref{eq:dual2}
\begin{equation}
   Ef(c_{1}\ldots c_{n})=\sum _{i=1}^{n}c_{i}-{\frac {1}{2}}\sum _{i=1}^{n}\sum _{j=1}^{n}S_{i}c_{i}k(x_{i},x_{j})S_{j}c_{j}m_{ij}. \label{eq:dual3}
\end{equation}

\subsubsection{Modifying kernel improves robustness against label noise}
Comparing this loss function and the ordinary loss function of \svm \eqref{eq:dual}, the only difference is to replace the kernel matrix~$K$ with our new proposed matrix~$Q:=K\circ M$, where $\circ$ denote the Hadamard product \citep{hastie01statisticallearning}.

%\subsubsection{Additional regularisation}


%This soft-margin \textsc{svm} is sub-optimal for our problem. We have a large set of data ($10,000$) comparing with the number of features ($784$). Hence, we build a modified \textsc{svm} that aims to minimise the following Hinge loss
%\begin{equation}
%\left[{\frac {1}{n}}\sum _{i=1}^{n}\max \left(0,10-y_{i}(w\cdot x_{i}-b)\right)\right]+\lambda \lVert %w\rVert ^{2}.   \label{eq:pri}
%\end{equation}
%The modified constant~$10$ requires the predictor~$w\cdot x_{i}-b$ to be as extreme as possible, i.e., it penalises wrongly classified samples. Moreover, it even penalises correctly classified samples with small gaps between data points and the dividing hyper-plane being small. 
%Define $\zeta _{i}:=\max \left(0,10-y_{i}(w\cdot x_{i}-b)\right)$. The prime problem of Hinge loss~\eqref{eq:pri} becomes a minimisation of
%\begin{equation}
%{\frac {1}{n}}\sum _{i=1}^{n}\zeta _{i}+\lambda \|w\|^{2}
%{\text{ subject to }}y_{i}(w\cdot x_{i}-b)\geq 10-\zeta _{i}\,{\text{ and }}\,\zeta _{i}\geq 0,\,{\text{for all }}i. \label{eq:pri2}
%\end{equation} 
%The modification is inspired by observing that the regularisation parameter~$\lambda$ has a negligible impact on the classification results for this problem. Hence we have more than enough data to train this complex model without over fitting.

%The modified \textsc{svm} aims to make the algorithm more robust to label noise, even though it may enlarge the generalisation error. Nevertheless, the large data set will assure us the generalisation error is within a reasonable magnitude.
%The parameters~$c_i$ are Lagrangian multipliers that enforcing the condition~$y_{i}(w\cdot x_{i}-b)\geq 10-\zeta _{i}$ in prime problem~\eqref{eq:pri2}.

%With this modification, the dual problem~\eqref{eq:dual3} of the loss function~\eqref{eq:pri} becomes
%\begin{equation*}
%   Ef(c_{1}\ldots c_{n})=10\sum _{i=1}^{n}c_{i}-{\frac {1}{2}}\sum _{i=1}^{n}\sum %_{j=1}^{n}S_{i}c_{i}k(x_{i},x_{j})S_{j}c_{j}m_{ij}. \label{eq:dual3}
%\end{equation*}
%From the dual prospective, we are weakening the contributions of the contaminated labels~$S_i$, hence making the algorithm more robust.



This method gives us an accuracy of $94.6\%$ on the testing data.


\subsection{Method 2: Importance Reweighting} \label{3rd}
This section applies theorems proved by \citet{liu2016classification} to construct a weighted loss that includes noise information~$\rho_0$ and $\rho_1$. 

\subsubsection{Sigmoid function estimates conditional probability}\label{sigmoid}
Define $D$ to be the probability density function of the clean data~$(X,Y)$ and $D_\rho$ to be that of contaminated data~$(X,S)$.

This section estimates the conditional probability~$P_{D_\rho}(S=y|X)$.

\citet{liu2016classification} provided three methods to estimate the conditional probability~$P_{D_\rho}(S=y|X)$. 
The first method implements a probabilistic regresion model. 
The second and third method both implement Bayesian formula~\eqref{eq:baye}.
\begin{equation*}
   P_{D_\rho}(S=y|X)=\frac{P_{D_\rho}(x|S=y)P_{D_\rho}(S=y)}{P(X)}.
\end{equation*}
However, the two methods are computationally different. The formal method requires to estimate two density functions~$P_{D_\rho}(X|S=y)$ and~$P(X)$ by kernel smoothing. Our data sets are high dimensional ($784$ and $3072$), so kernel smoothing suffers from the curse of dimensionality. The later method avoids kernel smoothing by estimating the ratio~$P_{D_\rho}(x|S=y)/P(X)$ directly through density ratio method \citep{liu2016classification}. For example, Section~\ref{method2} applies this method to estimate the flip rates~$\rho_0$ and $\rho_1$. Despite of the need of additional hyperparameters,  \citet{Sugiyama10densityratio} claims that the density ratio method is ``equivalent to the regression problem''. To keep our model simple and more interpretable, we implement a probabilistic regression model proposed in by \citet[Section~5.1]{liu2016classification}. 

We apply probability estimation method proposed by \citet{Platt99probabilisticoutputs}. We first train an ordinary \svm . We then train the parameters of an additional logistic regression model to map the \svm\ outputs into probabilities. We apply this approach rather than traditional logistic regression because Remark 1 given by \citet{liu2016classification} indicates the logistic regression ``does not perform well''.

\subsubsection{Reweighting coefficient improves robustness against label noise.}
{\color{red} ATTENDTION! I used $P$ in previous sections. Either use $P_D$ in all probability notations in this report or none of them. Also define $f$ which I have no clue what it is. Note that I have already occupied the letter $f$. Use something else if this is not the same $f$. Alternative change my previous letters $f$. Either way, Be consistent

After our discussion, I think the simplest way is just to delete all your $f$}.

To improve the robustness against label noise, \citet{liu2016classification} constructed a reweighting coefficient vector~
\begin{equation}
\beta(X,Y,S)=\frac{P_D(Y|X)}{P_{D_\rho}(S|X)}. \label{beta} 
\end{equation}
%in  to represent the expected risk if we can find the value of $\beta$
%where $D$ is the distribution of  and $D_\rho$ is the distribution of .
%The transformation deducted as follows:  
\\{\color{red} either use $\mathbb E$ for all expectation all none of them please fix}\\%
%\begin{eqnarray*}
%R_{l,D}(f) &=& \mathbb{E}_{(X,Y)\sim D}[l(f(X),Y)]\\
%           &=& \sum_{y}\int{P_D(X,Y=y)l(f(X),Y=y)}dX \\
%           &=& \sum_{y}\int{P_{D_\rho}(X,S=y)\frac{P_D(X,Y=y)}{P_{D_\rho}(X,S=y)}l(f(X),Y=y)}dX\\
%           &=& \mathbb{E}_{(X,S)\sim D_\rho}[\frac{P_D(X,Y=y)}{P_{D_\rho}(X,S=y)}l(f(X),S)]\\
%           &=& \mathbb{E}_{(X,S)\sim D_\rho}
%              [\beta l(f(X),S)] \\
%           &=& R_{\beta l,D_\rho}(f)
%\end{eqnarray*}
%Where $\beta=\frac{P_D(X,Y)}{P_{D_\rho}(X,S)}=\frac{P_D(Y|X)}{P_{D_\rho}(S|X)}$ as the distribution of $X$ does not change between $D_\rho$ and $D$.
%Now we can . 
%Although we can make an approximation for $D_\rho$ using the given data, we can not approximate the distribution $D$ directly. 
%We need to represent $P_D(Y|X)$ using $P_{D_\rho}(S|X)$ and the noise rates.
%\begin{equation}
%    \begin{aligned}
%    P(S=y|X) &= P(Y=y,S=y|X)+P(Y=-y,S=y|X)\\
%               &= P(S=y|X,Y=y)P(Y=y|X)
%                  +P(S=y|X,Y=-y)P(Y=-y|X)\\
%               &= (1-\rho_{y})P(Y=y|X)+\rho_{-y}[1-P(Y=y|X)]\\
%               &= (1-\rho_{y}-\rho{-y})P(Y=y|X)+\rho_{-y}
%    \end{aligned}
%\end{equation}
With some reasonable assumptions ({\color{red} what are the assumptions}), \citet{liu2016classification} also derived the distribution of the unobserved  true label using the observed label~$S$, the flip rates~$\rho_{0}$ and $\rho_{1}$
\begin{equation}
    P_D(Y=y|X)=\frac{P_{D_\rho}(S=y|X)-\rho_{1-y}}{1-\rho_{y}-\rho_{1-y}}\text{ where }y\in \left\{0,1\right\}.
\end{equation}
Substitute this estimation into the weighting coefficient~\eqref{beta}:
\begin{equation}
    \beta(X,Y,S)=\frac{P_{D_\rho}(S=y|X)-\rho_{1-y}}{(1-\rho_{y}-\rho_{1-y})P_{D_\rho}(S=y|X)}\text{ where }y\in \left\{0,1\right\}.
\end{equation}
Further substituting the conditional probability~$P_{D_\rho}(S=y|X)$ estimated in Section~\ref{sigmoid} gives reweighting coefficient~$\beta(X,Y,S)$. 
Recall from equation~\eqref{eq:decision} that  $g$ is the decision function. 
This reweighting coefficient~$\beta(X,Y,S)$ is then used to estimate the expected risk~$R_{\loss,D}(g)$ in the with the empirical risk $R_{\loss,D_\rho}(g)$
\begin{equation}
R_{\loss,D}(g) = R_{\beta \loss,D_\rho}(g). \label{eq:loss}
\end{equation}
This loss function allows us to estimate the true loss function~$R_{\loss,D}(g)$ without knowing the true labels~$Y$. 

\subsection{Method 3: samples filtering}\label{2nd}
Method 3 implements \textsc{svm} to select samples that are less likely contaminated by noises. 
%\subsubsection{Hinge loss is robust against label noise}

\subsubsection{Conditional probability filters samples}\label{2nd2}
Ordinary \textsc{svm} only gives a classification without revealing a probability that indicates the confidence of classification. 
\citet{Wu03probabilityestimates} proposed a five-fold cross-validation method to calculate the classification probabilities~$P(Y=1|X)$ for \textsc{svm}. 
Using this method, we calculated the probability~$P(Y=1|X)$ with label noise by an \textsc{svm} with Gaussian kernel. 

We have $10,000$ samples.
We rank the sample space of conditional probability~$P(Y=1|X)$, and denote the $3333$rd smallest and the $3333$rd greatest probability sample as $P(Y=1|X_{(3333)})$ and $P(Y=1|X_{(6667)})$, respectively. 
We only use a subset of samples where the predicted probability is very high or very low 
\begin{equation*}
\left\{X|P(Y=1|X)\geq P(Y=1|X_{(3333)}) \cup P(Y=1|X)\leq P(Y=1|X_{(6667)}) \right\}.
\end{equation*}
This method is inspired by the fact that the contaminated samples are more likely to have a probability~$P(Y=1|X)$ close to $0.5$. One third of sample are truncated because of the error rate~$P(\epsilon=1)=0.3\approx 1/3$. Note that this subset of sample is balanced.

\subsubsection{Matching predicted labels filters samples}
The predictions~$g(X)\neq S$ also suggests label noise might exist. Hence, we only use the subset where predicted classification match the observed label
\begin{equation*}
\left\{X|\left[P(Y=1|X)\geq P(Y=1|X_{(3333)}) \cup P(Y=1|X)\leq P(Y=1|X_{(6667)})\right] \cap g(X)=Y(X) \right\}.
\end{equation*}
We then further truncate this subset of samples so that the subset is balanced. This step is important because section~\ref{sec:1} shows that the original data set is also balanced.

Training our \textsc{svm} with Gaussian Kernel again with this subset of cleaned data gives the result.

This model is equivalent to minimise the loss function~\eqref{eq:loss} with the weighting coefficient
\begin{equation*}
\beta\begin{cases}
1 & \text{when }\left[P({Y}|X)\leq P(Y=1|X_{(3333)}) \cup P({Y}|X)\geq P(Y=1|X_{(6667)})\right] \cap g(X)=S,\\
0 & \text{when }P(Y=1|X_{(3333)})<P({Y}|X)<P(Y=1|X_{(6667)})\cup g(X)\neq S.
\end{cases}
\end{equation*}


This method gives us an accuracy of $95.0\%$ on the testing data.
%\subsubsection{Hinge loss if robust against label noise}


\subsection{Tuning hyperparameters}
The Kernel parameter for Gaussian Kernel~$\gamma$ is chosen to maximise the variance of Kernel matrix~$K(x_i,x_j)$ over all $i,j$. The regularisation parameter is chosen by grid search. The model seems to be insensitive to the regularisation parameter.

\subsection{Bootstrap constructs confidence intervals and hypothesis tests}\label{ci}
The assignment instruction asks us to compare the accuracy, denoted as $A$, of the proposed label noise robust algorithms. 
\subsubsection{Bootstrapping percentile confidence intervals}\label{ci}
To systematically compare the accuracy of the three methods introduced in Sections~\ref{1st}, \ref{3rd} and~\ref{2nd}, we construct the $95\%$ bootstrapping percentile confidence intervals for accuracy~$A$. The idea of bootstrapping  is straightforward---we resample a subset of $8$ samples among the sample space of the $16$ accuracy results and calculate their mean. We repeat this process $1000$ times. The $2.5\%$ and $97.5\%$ percentiles of the $1000$ re-sampled means are then the bootstrapping percentile confidence interval
\begin{equation}
({A}^*_{2.5}, {A}^*_{97.5}), \label{eq:boot}
\end{equation}
where $A^*_{\alpha}$ is the $\alpha$ percentile of the bootstrapped distribution from our sample space with $16$ accuracy result from Monte-Carlo simulations.

Bootstrapping does not require the sample space follows specific distributions. We apply this nonparametric method to construct confidence interval here because we do not know about the exact distributions of accuracy~$A$.

\subsubsection{Kolmogorov-Smirnov test compares the accuracy of algorithms}
We implement the Kolmogorov-Smirnov test to test the hypothesis that the algorithms proposed in Section~\ref{method} have different accuracy.  Again, Kolmogorov-Smirnov test is distribution free, so we do not need to know the distributions of the evaluation metrics.

Let $A_{ij}$ be the accuracy generated from our {$i$}th algorithm from the $j$th Monte-Carlo simulation. Denote the indicator function~$1_{A_{ij} \leq x}$ as the binary result indicating whether $A_{ij} \leq x$ is true. We define the empirical distribution of accuracy results generated by algorithm~$i$ as
\begin{equation}\label{epdf}
  \hat{F}_{i}(x)=\frac{1}{n}\sum_{j=1}^{16}1_{A_{ij} \leq x}.
\end{equation}
The test statistic is the supremum among the differences of the empirical distribution generated using empirical distribution~\eqref{epdf} of $i_1$th and $i_2$th algorithm \citep{Walck:1996cca}
\begin{equation}\label{teststatistic}
D=\sup _{x}\left|F_{i_1}(x)-F_{i_2}(x)\right|.
\end{equation}
We compare the test statistics~$D$ with the critical value of $0.433$, which corresponds to $16$ samples and a $95\%$ of confidence level. We reject the null hypotheses that the two algorithms produce the same accuracy~$A$ with $95\%$ confidence level if the test statistics~$D>0.433$. 
%The technique is also applied to perform one tail test to test whether $i_1$th algorithm is more accurate than $i_2$th algorithm. In this case, the test statistic is the supremum
%\begin{equation}\label{teststatistic}
%D^+=\sup _{x}F_{i_1}(x)-F_{i_2}(x).
%\end{equation}
\section{Experiments}\label{result}

\subsection{Experiment Setting}
\subsection{Compare Images}
\subsection{Discuss flip rate}

\subsection{Hayperparameter Tuning}
Just identify the haperparameter number.

\subsection{Compare Results}
\subsubsection{Accuracy}
\subsubsection{Running time}
compare photos
discuss pca
heruistic no need to know rho.


\begin{figure} 
    \centering
	\includegraphics[scale=.8]{hpc}
	\caption{HPC...}
	\label{fig:HPC}
\end{figure}

\begin{table}
\centering
 	\caption{Hypothesis test}   
	\begin{tabular}{lllll}
\toprule
Data & $H_0$ & $D$ & P-value & Test result\\
\midrule
 & $A_1= A_2$  &0.3125 & 0.4154 & Fail to reject\\
 
 \textsc{mnist} & $A_1= A_3$ & 0.625 & 0.0038 & Reject\\
 
  & $A_2= A_3$ & 0.3125 & 0.4154 & Fail to reject\\
\midrule
   & $A_1= A_2$ & 0.6875 & 0.0010 & Reject\\

 \textsc{cifar}  & $A_1= A_3$ & 0.5 & 0.0366 & Reject\\

  &  $A_2=A_3$  & 0.6875 & 0.0010 & Reject\\
\bottomrule
\end{tabular} 

	\label{tab:HypothesisTest}
\end{table}

\begin{table}
	\caption{Mean sd}
	\label{tab:Meansd}
% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
\centering
\begin{tabular}{@{}lll@{}}
\toprule
Mean  & Standard deviation & Confidence interval \\ \midrule
0.938 & 0.003              & (0.936,0.939)       \\
0.942 & 0.003              & (0.941,0.944)       \\
0.94  & 0.003              & (0.939,0.942)       \\
0.835 & 0.004              & (0.833.0.837)       \\
0.832 & 0.008              & (0.829,0.836)       \\
0.844 & 0.005              & (0.841,0.846)       \\ \bottomrule
\end{tabular}

\end{table}



\begin{figure}
    
	%\includegraphics[scale=0.9]{boxplot}
	\centering
    \includegraphics[scale=0.8]{boxplotll}%maybe use the large one
	\caption{Boxplot}
	\label{fig:Boxplot}
\end{figure}

\begin{figure}   
    \centering
	\includegraphics[scale=0.9]{histo}
	\caption{Density function from kernel smoothing}
	\label{fig:Density function from kernel smoothing}
\end{figure}

{\color{red} please plot the cifar with and without PCA, put them into one graph and compare. codes are already available. just run them and save and insert.}\\
We use the methods,\ref{1st}, \ref{2nd} and \ref{3rd}, to conduct experiments on two datasets, fashion-mnist and \textsc{cifar}.
Both datasets are re-organized to have two classes 0 and 1. 
For clearer notation, we refer to class 0 as -1 and class 1 as +1. 
Both datasets have flip rates $\rhoz=0.2$ and $\rhoo=0.4$.
The fashion-mnist has dimension $d=784$, while \textsc{cifar} has $d=3072$. 
{\color{red} original image}
As mentioned in section \ref{preproc}, we need to run \textsc{pca} on \textsc{cifar} to reduce the dimensionality.
{\color{red} pca image. decribe the difference}
Then we scale the image
{\color{red} standardised image. decribe the difference} \\ \\
To provide a more rigorous evaluation on performance, we train the model $16$ times using each method on each dataset and calculate the mean and standard deviation of the results.
We randomly sample $80\%$ of the training data for training each model.
To reduce the running time, we use multi-threading programming and train the $16$ models simultaneously. \\ \\
Table \ref{tab:Meansd} shows the mean, standard deviation and $95\%$ confidence interval of the accuracy result from testing the $16$ models on clean testing set for each experiment. 
Overall, the accuracy of the fashion-mnist experiments is higher than that of the \textsc{cifar} experiments possibly due to the complexity difference.
The relabelling method outperforms the other two on fashion-mnist data and the importance reweighting method outperforms the other two on \textsc{cifar} dataset.
Table \ref{tab:HypothesisTest} shows the hypothesis test results on the accuracy statistics. 
It shows that relabelling algorithm classifies the noisy fashion-mnist data more accurately than the expectation maximisation method with high probability.
Also, reweighting method classifies the noisy \textsc{cifar} data more accurately than the expectation maximisation method and relabelling classifies the data least accurately with high probability. 
Figure \ref{fig:Boxplot} is the boxplot of all experiment results. 
Beyond what we see from the tables, we find from the boxplot that for the relabelling method, the results of \textsc{cifar} experiments have larger interquartile range \textsc{iqr} than that of fashion-mnist experiments. 
\textsc{iqr}'s are not so different across datasets for the other two methods. 
This means the relabelling method may not perform as stable as the other two methods when classifying the \textsc{cifar} dataset. 
Further experiments may be conducted in future work to verify this. 
Then we estimate the density function using kernel smoothing and plot figure \ref{fig:Density function from kernel smoothing}.
For fashion-mnist dataset, all three methods have similar accuracy distribution with relabelling having a slightly better performance.
For \textsc{cifar} dataset, the accuracy distribution of reweighting method dominates the other two.

\section{Conclusion}
\label{headings}



\bibliographystyle{unsrtnat}
\bibliography{reference}

\end{document}
