{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca explained variance: 0.8560751474986309\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Sat Oct 13 00:24:24 2018\n",
    "\n",
    "@author: chenc\n",
    "reweighting method from tut 2\n",
    "dataset1 improves the accuracy  to 0.946\n",
    "dataset1 improves the accuracy  to 0.855\n",
    "\"\"\"\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Spyder Editor\n",
    "\n",
    "This is a temporary script file.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import IncrementalPCA as PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from random import sample\n",
    "dset=2\n",
    "plot=0\n",
    "\n",
    "if dset==1:\n",
    "    dataset = np.load('../input_data/mnist_dataset.npz')\n",
    "    size_image=28\n",
    "    dim_image=1 \n",
    "else:\n",
    "    dataset = np.load('../input_data/cifar_dataset.npz')\n",
    "    size_image=32\n",
    "    dim_image=3\n",
    "#size_image=28\n",
    "#dim_image=1\n",
    "\n",
    "Xtr = dataset ['Xtr'].astype(float)\n",
    "Str = dataset ['Str'].ravel()\n",
    "Xts = dataset ['Xts'].astype(float)\n",
    "Yts = dataset ['Yts'].ravel()\n",
    "scaler = StandardScaler()\n",
    "Xts = scaler.fit_transform(Xts.T).T\n",
    "Xtr = scaler.fit_transform(Xtr.T).T\n",
    "\n",
    "if dset==2:\n",
    "    #Xtr=Xtr.reshape(10000,dim_image,size_image,size_image).transpose([0,2, 3, 1]).mean(3).reshape(10000,size_image*size_image)\n",
    "    #Xts=Xts.reshape(2000,dim_image,size_image,size_image).transpose([0,2, 3, 1]).mean(3).reshape(2000,size_image*size_image)\n",
    "    pca = PCA(n_components=100)\n",
    "    pca.fit(Xtr)\n",
    "    Xtr=pca.transform(Xtr)\n",
    "    Xts=pca.transform(Xts)\n",
    "    print('pca explained variance:',sum(pca.explained_variance_ratio_))\n",
    "    if plot:\n",
    "        xplot=scaler.fit_transform(pca.inverse_transform(Xts).T).T\n",
    "\n",
    "#Xts = scaler.fit_transform(Xts.T).T\n",
    "#Xtr = scaler.fit_transform(Xtr.T).T\n",
    "\n",
    "##1plt.jet()\n",
    "\n",
    "if plot:\n",
    "    plt.figure()\n",
    "    for i in range(0,30):\n",
    "        image=xplot[i,].reshape(dim_image,size_image,size_image).transpose([1, 2, 0])\n",
    "        plt.subplot(5, 6, i+1)\n",
    "        plt.imshow(image[:,:,:],interpolation='bicubic')\n",
    "        plt.title(Yts[i])\n",
    "\n",
    "#indices = np.random.choice(Xts.shape[0],int(Xts.shape[0]*0.8), replace=False)\n",
    "\n",
    "def estimateBeta(S,prob,rho0,rho1):\n",
    "    S=S.astype(int)\n",
    "    rho=np.array([rho1,rho0])\n",
    "    #rho=np.tile(np.array([rho1, rho0]).reshape(-1,1),700).T\n",
    "    #print(rho[S])\n",
    "    \n",
    "    #print(S)\n",
    "    prob=prob[:,0]*(1-S[:])+prob[:,1]*(S[:])\n",
    "    #print(sum(prob>.5)/700)\n",
    "    #print(S[0:11])\n",
    "    beta=(prob[:]-rho[S].ravel())/(1-rho0-rho1)/prob[:]\n",
    "    return beta\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running for fashion_mnist\n",
      "run  0  validation score after reweighting: 0.589\n",
      "run  1  validation score after reweighting: 0.6025\n",
      "run  2  validation score after reweighting: 0.606\n",
      "run  3  validation score after reweighting: 0.602\n",
      "run  4  validation score after reweighting: 0.599\n",
      "average score:  0.5997\n",
      "running for cifar\n",
      "run  0  validation score after reweighting: 0.63\n",
      "run  1  validation score after reweighting: 0.6325\n",
      "run  2  validation score after reweighting: 0.646\n",
      "run  3  validation score after reweighting: 0.651\n",
      "run  4  validation score after reweighting: 0.6395\n",
      "average score:  0.6397999999999999\n"
     ]
    }
   ],
   "source": [
    "# dset chooses dataset. num_run determines the number of iterations.\n",
    "def cv_reweighting(dset, num_run):\n",
    "    if dset==1:\n",
    "        clf = svm.SVC(C=.8,gamma=0.000225,probability=True)\n",
    "        print('running for fashion_mnist')\n",
    "    else:\n",
    "        #removed 'gamma=scale'. should be the default.\n",
    "        clf = svm.SVC(probability=True,C=.4,gamma=scale)\n",
    "        print('running for cifar')\n",
    "    \n",
    "    val_score=np.zeros(num_run)\n",
    "    \n",
    "    for run in range(num_run):\n",
    "        X_train, X_val, y_train, y_val = train_test_split(Xtr, Str, test_size=0.2)\n",
    "\n",
    "        clf.fit(X_train,y_train)\n",
    "        #print(clf.score(Xts,Yts))\n",
    "        #clf.score(Xtr,Str)\n",
    "        probS = clf.predict_proba(X_train)\n",
    "        weights = estimateBeta(y_train, probS, 0.2, 0.4)\n",
    "        #print(weights.shape)\n",
    "\n",
    "        for i in range(len(weights)):\n",
    "            if weights[i] < 0:\n",
    "                weights[i] = 0.0    \n",
    "                \n",
    "        if dset==2:\n",
    "            clf = svm.SVC(gamma=0.000225,C=0.8,probability=True)\n",
    "        else:\n",
    "            clf = svm.SVC(gamma=0.00865,C=.4,probability=True)\n",
    "            \n",
    "        clf.fit(X_train,y_train,sample_weight=weights)\n",
    "        val_score[run]=clf.score(X_val,y_val)\n",
    "        print('run ',run,' validation score after reweighting:',val_score[run])\n",
    "        #clf.score(Xtr,Str)\n",
    "        # to accuracy 94.6 for dataset 1\n",
    "        # 85.5 for dataset 2.\n",
    "    average_score=np.mean(val_score)\n",
    "    print('average score: ',average_score)\n",
    "    return average_score, clf\n",
    "\n",
    "\n",
    "average_score,clf1=cv_reweighting(1, 5)\n",
    "average_score,clf2=cv_reweighting(2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for dataset 1:  0.5\n",
      "score for dataset 2:  0.842\n"
     ]
    }
   ],
   "source": [
    "print(\"score for dataset 1: \",clf1.score(Xts,Yts))\n",
    "print(\"score for dataset 2: \",clf2.score(Xts,Yts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
